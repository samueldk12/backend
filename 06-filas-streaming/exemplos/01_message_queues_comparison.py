"""
MÃ³dulo 06 - Filas e Streaming: ComparaÃ§Ã£o de Message Queues

Este exemplo mostra implementaÃ§Ãµes reais de:
1. Celery com Redis (task queue mais popular)
2. RabbitMQ com pika (message broker robusto)
3. ComparaÃ§Ã£o de padrÃµes (publish/subscribe, fanout, direct)
4. IdempotÃªncia e retry strategies
5. Dead Letter Queue (DLQ)

Execute:
    # Terminal 1: Inicie o Redis
    docker run -d -p 6379:6379 redis:alpine

    # Terminal 2: Inicie o worker Celery
    celery -A 01_message_queues_comparison:celery_app worker --loglevel=info

    # Terminal 3: Execute o script
    python 01_message_queues_comparison.py
"""

import time
import json
from datetime import datetime
from typing import List, Dict, Any
from enum import Enum
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================================
# EXEMPLO 1: Celery com Redis (Mais Usado em Python)
# ============================================================================

from celery import Celery, Task
from celery.exceptions import Retry

# ConfiguraÃ§Ã£o do Celery
celery_app = Celery(
    'tasks',
    broker='redis://localhost:6379/0',  # Onde ficam as filas
    backend='redis://localhost:6379/1'  # Onde ficam os resultados
)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='America/Sao_Paulo',
    enable_utc=True,

    # ConfiguraÃ§Ãµes importantes
    task_acks_late=True,  # Confirma task sÃ³ apÃ³s completar (nÃ£o ao receber)
    worker_prefetch_multiplier=1,  # Pega 1 task por vez (melhor distribuiÃ§Ã£o)
    task_reject_on_worker_lost=True,  # Rejeita task se worker morrer
)


# ----------------------------------------------------------------------------
# Task Simples
# ----------------------------------------------------------------------------

@celery_app.task(name='tasks.send_email')
def send_email(to: str, subject: str, body: str):
    """
    Task simples: enviar email

    CaracterÃ­sticas:
    - AssÃ­ncrona: retorna imediatamente
    - Worker processa em background
    - Retry automÃ¡tico em caso de falha
    """
    logger.info(f"ğŸ“§ Enviando email para {to}: {subject}")
    time.sleep(2)  # Simula envio
    logger.info(f"âœ… Email enviado para {to}")
    return {"status": "sent", "to": to}


# ----------------------------------------------------------------------------
# Task com Retry e Exponential Backoff
# ----------------------------------------------------------------------------

@celery_app.task(
    name='tasks.fetch_external_api',
    bind=True,  # Permite acessar self (task instance)
    max_retries=5,
    default_retry_delay=60  # 1 minuto
)
def fetch_external_api(self, url: str):
    """
    Task com retry strategy

    Retry com exponential backoff:
    - Tentativa 1: imediato
    - Tentativa 2: 2^1 = 2 segundos
    - Tentativa 3: 2^2 = 4 segundos
    - Tentativa 4: 2^3 = 8 segundos
    - Tentativa 5: 2^4 = 16 segundos
    """
    try:
        logger.info(f"ğŸŒ Fetching {url} (tentativa {self.request.retries + 1}/5)")

        # Simula falha intermitente (50% de chance)
        import random
        if random.random() < 0.5:
            raise ConnectionError("API temporariamente indisponÃ­vel")

        # Simula sucesso
        time.sleep(1)
        logger.info(f"âœ… API fetch successful: {url}")
        return {"url": url, "status": "success"}

    except ConnectionError as exc:
        # Exponential backoff: 2^retry_count
        countdown = 2 ** self.request.retries
        logger.warning(f"âš ï¸  Tentativa {self.request.retries + 1} falhou. Retry em {countdown}s")

        # Raise Retry exception
        raise self.retry(exc=exc, countdown=countdown)


# ----------------------------------------------------------------------------
# Task com IdempotÃªncia (Executar mÃºltiplas vezes = mesmo resultado)
# ----------------------------------------------------------------------------

from redis import Redis
redis_client = Redis(host='localhost', port=6379, decode_responses=True)

@celery_app.task(name='tasks.process_payment')
def process_payment(payment_id: str, amount: float):
    """
    Task idempotente: pode executar mÃºltiplas vezes sem problemas

    IdempotÃªncia garante que:
    - Se task for re-executada (ex: worker crash), nÃ£o causa duplicaÃ§Ã£o
    - Usa Redis para rastrear payments jÃ¡ processados
    """
    lock_key = f"payment:lock:{payment_id}"

    # Tentar adquirir lock (SETNX = SET if Not eXists)
    acquired = redis_client.set(lock_key, "processing", nx=True, ex=300)  # 5min TTL

    if not acquired:
        logger.warning(f"âš ï¸  Payment {payment_id} jÃ¡ estÃ¡ sendo processado")
        return {"status": "duplicate", "payment_id": payment_id}

    try:
        logger.info(f"ğŸ’³ Processando pagamento {payment_id}: R${amount}")
        time.sleep(2)  # Simula processamento

        # Salvar resultado
        redis_client.set(f"payment:result:{payment_id}", "success", ex=86400)  # 24h

        logger.info(f"âœ… Pagamento {payment_id} processado com sucesso")
        return {"status": "success", "payment_id": payment_id, "amount": amount}

    finally:
        # Liberar lock
        redis_client.delete(lock_key)


# ----------------------------------------------------------------------------
# Task Chain: Encadear tasks (output de uma vira input da outra)
# ----------------------------------------------------------------------------

@celery_app.task(name='tasks.download_video')
def download_video(video_url: str) -> str:
    """Passo 1: Baixar vÃ­deo"""
    logger.info(f"â¬‡ï¸  Baixando vÃ­deo: {video_url}")
    time.sleep(2)
    video_path = f"/tmp/video_{int(time.time())}.mp4"
    logger.info(f"âœ… VÃ­deo baixado: {video_path}")
    return video_path


@celery_app.task(name='tasks.encode_video')
def encode_video(video_path: str) -> str:
    """Passo 2: Encodar vÃ­deo"""
    logger.info(f"ğŸ¬ Encodando vÃ­deo: {video_path}")
    time.sleep(3)
    encoded_path = video_path.replace(".mp4", "_encoded.mp4")
    logger.info(f"âœ… VÃ­deo encodado: {encoded_path}")
    return encoded_path


@celery_app.task(name='tasks.upload_to_cdn')
def upload_to_cdn(encoded_path: str) -> str:
    """Passo 3: Upload para CDN"""
    logger.info(f"â˜ï¸  Fazendo upload: {encoded_path}")
    time.sleep(2)
    cdn_url = f"https://cdn.example.com/{encoded_path.split('/')[-1]}"
    logger.info(f"âœ… Upload completo: {cdn_url}")
    return cdn_url


@celery_app.task(name='tasks.notify_user')
def notify_user(cdn_url: str, user_id: int):
    """Passo 4: Notificar usuÃ¡rio"""
    logger.info(f"ğŸ”” Notificando usuÃ¡rio {user_id}: vÃ­deo disponÃ­vel em {cdn_url}")
    time.sleep(1)
    logger.info(f"âœ… UsuÃ¡rio {user_id} notificado")
    return {"status": "notified", "user_id": user_id, "cdn_url": cdn_url}


# ----------------------------------------------------------------------------
# Exemplos de Uso
# ----------------------------------------------------------------------------

def exemplo_celery_basico():
    """Exemplo 1: Task assÃ­ncrona simples"""
    print("\n" + "="*70)
    print("EXEMPLO 1: Task AssÃ­ncrona Simples")
    print("="*70)

    # Enviar task para fila (retorna imediatamente)
    result = send_email.delay("joao@example.com", "Bem-vindo", "OlÃ¡ JoÃ£o!")

    print(f"Task enviada! Task ID: {result.id}")
    print(f"Estado inicial: {result.state}")  # PENDING

    # Aguardar resultado (bloqueante)
    print("Aguardando conclusÃ£o...")
    output = result.get(timeout=10)
    print(f"Resultado: {output}")
    print(f"Estado final: {result.state}")  # SUCCESS


def exemplo_celery_retry():
    """Exemplo 2: Task com retry"""
    print("\n" + "="*70)
    print("EXEMPLO 2: Task com Retry e Exponential Backoff")
    print("="*70)

    result = fetch_external_api.delay("https://api.example.com/data")
    print(f"Task enviada! Task ID: {result.id}")

    try:
        output = result.get(timeout=30)
        print(f"âœ… Sucesso: {output}")
    except Exception as e:
        print(f"âŒ Falha apÃ³s retries: {e}")


def exemplo_celery_idempotencia():
    """Exemplo 3: Task idempotente"""
    print("\n" + "="*70)
    print("EXEMPLO 3: IdempotÃªncia (executar 2x = mesmo resultado)")
    print("="*70)

    payment_id = "PAY-123456"

    # Enviar task 2 vezes (simula retry acidental)
    result1 = process_payment.delay(payment_id, 100.00)
    result2 = process_payment.delay(payment_id, 100.00)  # Duplicata!

    print(f"Task 1: {result1.get()}")
    print(f"Task 2: {result2.get()}")  # Deve detectar duplicata


def exemplo_celery_chain():
    """Exemplo 4: Chain de tasks (pipeline)"""
    print("\n" + "="*70)
    print("EXEMPLO 4: Chain de Tasks (Pipeline)")
    print("="*70)

    from celery import chain

    # Chain: download -> encode -> upload -> notify
    # Output de cada task vira input da prÃ³xima
    workflow = chain(
        download_video.s("https://example.com/video.mp4"),
        encode_video.s(),  # Recebe output de download_video
        upload_to_cdn.s(),  # Recebe output de encode_video
        notify_user.s(user_id=123)  # Recebe output de upload_to_cdn
    )

    result = workflow.apply_async()
    print(f"Workflow iniciado! Task ID: {result.id}")

    print("Processando... (pode demorar ~10s)")
    final_result = result.get(timeout=20)
    print(f"âœ… Workflow completo: {final_result}")


# ============================================================================
# EXEMPLO 2: Dead Letter Queue (DLQ)
# ============================================================================

@celery_app.task(
    name='tasks.risky_task',
    bind=True,
    max_retries=3,
    autoretry_for=(Exception,),
    retry_backoff=True,
    retry_backoff_max=600,
    retry_jitter=True
)
def risky_task(self, data: dict):
    """
    Task que pode falhar permanentemente

    Se falhar apÃ³s todos os retries:
    - Vai para Dead Letter Queue (DLQ)
    - DLQ permite anÃ¡lise manual
    - Pode ser re-enfileirada depois de fix
    """
    try:
        logger.info(f"ğŸ² Executando risky task: {data}")

        # Simula erro permanente (ex: data invÃ¡lida)
        if not data.get("valid"):
            raise ValueError("Invalid data")

        time.sleep(1)
        return {"status": "success", "data": data}

    except Exception as exc:
        logger.error(f"âŒ Risky task falhou: {exc}")

        # Se esgotou retries, enviar para DLQ
        if self.request.retries >= self.max_retries:
            send_to_dlq.delay(task_name=self.name, data=data, error=str(exc))
            logger.error(f"ğŸ’€ Task enviada para DLQ apÃ³s {self.max_retries} retries")

        raise


@celery_app.task(name='tasks.send_to_dlq')
def send_to_dlq(task_name: str, data: dict, error: str):
    """Envia task falhada para Dead Letter Queue"""
    dlq_entry = {
        "task": task_name,
        "data": data,
        "error": error,
        "timestamp": datetime.utcnow().isoformat()
    }

    # Salvar no Redis (ou DB, S3, etc)
    redis_client.lpush("dlq:failed_tasks", json.dumps(dlq_entry))
    logger.info(f"ğŸ’€ Task salva na DLQ: {task_name}")


# ============================================================================
# EXEMPLO 3: PadrÃµes de Mensageria
# ============================================================================

class MessagePattern(Enum):
    """PadrÃµes comuns de mensageria"""
    POINT_TO_POINT = "point_to_point"  # 1 producer â†’ 1 consumer
    PUBLISH_SUBSCRIBE = "pub_sub"      # 1 producer â†’ N consumers
    FANOUT = "fanout"                   # Broadcast para todos
    DIRECT = "direct"                   # Routing por chave


def exemplo_fanout_pattern():
    """
    Fanout: broadcast para mÃºltiplos consumers

    Caso de uso: Notificar mÃºltiplos serviÃ§os sobre um evento

    Evento: "Novo usuÃ¡rio registrado"
    Consumers:
    - ServiÃ§o de email (enviar boas-vindas)
    - ServiÃ§o de analytics (rastrear signup)
    - ServiÃ§o de onboarding (iniciar tutorial)
    """
    print("\n" + "="*70)
    print("EXEMPLO 5: Fanout Pattern (Broadcast)")
    print("="*70)

    from celery import group

    user_data = {"id": 123, "email": "joao@example.com", "name": "JoÃ£o"}

    # Group: executar tasks em paralelo (nÃ£o em sequÃªncia)
    tasks = group(
        send_welcome_email.s(user_data),
        track_signup.s(user_data),
        start_onboarding.s(user_data)
    )

    result = tasks.apply_async()
    print(f"Broadcast enviado! {len(result)} tasks executando em paralelo")

    # Aguardar todas
    results = result.get(timeout=10)
    print(f"âœ… Todas as tasks completaram: {results}")


@celery_app.task(name='tasks.send_welcome_email')
def send_welcome_email(user_data: dict):
    logger.info(f"ğŸ“§ Enviando email de boas-vindas para {user_data['email']}")
    time.sleep(1)
    return {"service": "email", "status": "sent"}


@celery_app.task(name='tasks.track_signup')
def track_signup(user_data: dict):
    logger.info(f"ğŸ“Š Rastreando signup no analytics: user {user_data['id']}")
    time.sleep(1)
    return {"service": "analytics", "status": "tracked"}


@celery_app.task(name='tasks.start_onboarding')
def start_onboarding(user_data: dict):
    logger.info(f"ğŸ“ Iniciando onboarding para user {user_data['id']}")
    time.sleep(1)
    return {"service": "onboarding", "status": "started"}


# ============================================================================
# EXEMPLO 4: Monitoramento
# ============================================================================

from celery.events.snapshot import Polaroid

@celery_app.task(name='tasks.monitor_queue_health')
def monitor_queue_health():
    """
    Monitora saÃºde das filas

    MÃ©tricas importantes:
    - Tamanho da fila (backlog)
    - Taxa de processamento
    - Taxa de erro
    - Workers ativos
    """
    from celery import current_app

    # Inspecionar workers
    inspect = current_app.control.inspect()

    active = inspect.active()  # Tasks sendo executadas
    scheduled = inspect.scheduled()  # Tasks agendadas
    registered = inspect.registered()  # Tasks disponÃ­veis

    stats = {
        "active_tasks": sum(len(tasks) for tasks in (active or {}).values()),
        "scheduled_tasks": sum(len(tasks) for tasks in (scheduled or {}).values()),
        "registered_tasks": len(list((registered or {}).values())[0]) if registered else 0,
        "timestamp": datetime.utcnow().isoformat()
    }

    logger.info(f"ğŸ“Š Queue Health: {stats}")
    return stats


# ============================================================================
# COMPARAÃ‡ÃƒO: Celery vs RabbitMQ vs Kafka
# ============================================================================

def print_comparison():
    """Imprime comparaÃ§Ã£o de sistemas de fila"""
    print("\n" + "="*70)
    print("COMPARAÃ‡ÃƒO: Celery vs RabbitMQ vs Kafka vs AWS SQS")
    print("="*70)

    comparison = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CaracterÃ­stica â”‚    Celery    â”‚   RabbitMQ   â”‚     Kafka    â”‚    AWS SQS   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tipo           â”‚ Task Queue   â”‚ Message      â”‚ Event Stream â”‚ Message      â”‚
â”‚                â”‚              â”‚ Broker       â”‚              â”‚ Queue        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Throughput     â”‚ ~50k msg/s   â”‚ ~50k msg/s   â”‚ ~1M msg/s    â”‚ ~300 msg/s   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LatÃªncia       â”‚ <10ms        â”‚ <5ms         â”‚ <10ms        â”‚ ~100ms       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PersistÃªncia   â”‚ Redis/RMQ    â”‚ Sim          â”‚ Sim (log)    â”‚ Sim          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Order          â”‚ âŒ NÃ£o       â”‚ âœ… Por queue â”‚ âœ… Por parti â”‚ âŒ FIFO queueâ”‚
â”‚ Guarantee      â”‚              â”‚              â”‚ Ã§Ã£o          â”‚ (separado)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Replay         â”‚ âŒ NÃ£o       â”‚ âŒ NÃ£o       â”‚ âœ… Sim       â”‚ âŒ NÃ£o       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Complexidade   â”‚ â­â­         â”‚ â­â­â­       â”‚ â­â­â­â­     â”‚ â­           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Escalabilidade â”‚ MÃ©dia        â”‚ MÃ©dia        â”‚ Alta         â”‚ Alta         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Custo          â”‚ Baixo        â”‚ Baixo        â”‚ MÃ©dio        â”‚ Pay-per-use  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Use quando     â”‚ Tasks        â”‚ Mensageria   â”‚ Event        â”‚ Serverless,  â”‚
â”‚                â”‚ assÃ­ncronas, â”‚ entre        â”‚ Sourcing,    â”‚ AWS nativo   â”‚
â”‚                â”‚ job queue    â”‚ serviÃ§os     â”‚ analytics    â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“š GUIA DE DECISÃƒO:

âœ… Use CELERY quando:
   - Precisa processar tasks assÃ­ncronas em Python
   - Background jobs (emails, reports, etc)
   - Retry e scheduling sÃ£o importantes
   - FÃ¡cil integraÃ§Ã£o com Django/FastAPI
   - 80% dos casos de task queue

âœ… Use RABBITMQ quando:
   - Mensageria entre microserviÃ§os
   - Precisa routing complexo
   - Garantias de entrega sÃ£o crÃ­ticas
   - Language-agnostic (Java, Go, Node, etc)

âœ… Use KAFKA quando:
   - Event Sourcing / CQRS
   - Analytics em tempo real
   - Precisa replay de eventos
   - AltÃ­ssimo throughput (milhÃµes de msgs/s)
   - Stream processing

âœ… Use AWS SQS quando:
   - Infraestrutura toda na AWS
   - Serverless (Lambda)
   - NÃ£o quer gerenciar infra
   - NÃ£o precisa alta performance
"""
    print(comparison)


# ============================================================================
# PADRÃ•ES AVANÃ‡ADOS
# ============================================================================

def exemplo_saga_pattern():
    """
    Saga Pattern: TransaÃ§Ã£o distribuÃ­da

    Caso de uso: Processar pedido e-commerce

    Passos:
    1. Reservar estoque
    2. Processar pagamento
    3. Criar ordem de envio
    4. Notificar usuÃ¡rio

    Se qualquer passo falhar: executar compensaÃ§Ã£o (rollback)
    """
    print("\n" + "="*70)
    print("EXEMPLO 6: Saga Pattern (TransaÃ§Ã£o DistribuÃ­da)")
    print("="*70)

    from celery import chain, chord

    order_data = {"order_id": "ORD-123", "user_id": 456, "items": [1, 2, 3]}

    # Chord: executar tasks em paralelo, depois executar callback
    workflow = chord([
        reserve_stock.s(order_data),
        process_payment_saga.s(order_data),
        create_shipment.s(order_data)
    ])(finalize_order.s(order_data))  # Callback apÃ³s todas completarem

    result = workflow.get(timeout=15)
    print(f"âœ… Saga completa: {result}")


@celery_app.task(name='tasks.reserve_stock')
def reserve_stock(order_data: dict):
    logger.info(f"ğŸ“¦ Reservando estoque para order {order_data['order_id']}")
    time.sleep(1)
    # Se falhar: raise exception (saga serÃ¡ compensada)
    return {"step": "stock", "status": "reserved"}


@celery_app.task(name='tasks.process_payment_saga')
def process_payment_saga(order_data: dict):
    logger.info(f"ğŸ’³ Processando pagamento para order {order_data['order_id']}")
    time.sleep(2)
    return {"step": "payment", "status": "processed"}


@celery_app.task(name='tasks.create_shipment')
def create_shipment(order_data: dict):
    logger.info(f"ğŸšš Criando ordem de envio para order {order_data['order_id']}")
    time.sleep(1)
    return {"step": "shipment", "status": "created"}


@celery_app.task(name='tasks.finalize_order')
def finalize_order(results: List[dict], order_data: dict):
    """Callback: executado apÃ³s todas as tasks do chord"""
    logger.info(f"âœ… Finalizando order {order_data['order_id']}")
    logger.info(f"Resultados: {results}")
    return {"order_id": order_data['order_id'], "status": "completed", "steps": results}


# ============================================================================
# MAIN: Executar Exemplos
# ============================================================================

if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    MÃ“DULO 06: FILAS E STREAMING                          â•‘
â•‘                Exemplos de Message Queues com Celery                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸  IMPORTANTE: Antes de executar, inicie:
   1. Redis: docker run -d -p 6379:6379 redis:alpine
   2. Celery Worker: celery -A 01_message_queues_comparison:celery_app worker --loglevel=info

Escolha um exemplo para executar:
1. Task assÃ­ncrona simples
2. Task com retry e exponential backoff
3. IdempotÃªncia (executar 2x = mesmo resultado)
4. Chain de tasks (pipeline)
5. Fanout pattern (broadcast)
6. Saga pattern (transaÃ§Ã£o distribuÃ­da)
7. Ver comparaÃ§Ã£o de sistemas

Digite o nÃºmero (ou 0 para sair): """)

    choice = input().strip()

    if choice == "1":
        exemplo_celery_basico()
    elif choice == "2":
        exemplo_celery_retry()
    elif choice == "3":
        exemplo_celery_idempotencia()
    elif choice == "4":
        exemplo_celery_chain()
    elif choice == "5":
        exemplo_fanout_pattern()
    elif choice == "6":
        exemplo_saga_pattern()
    elif choice == "7":
        print_comparison()
    elif choice == "0":
        print("ğŸ‘‹ AtÃ© logo!")
    else:
        print("âŒ OpÃ§Ã£o invÃ¡lida")

    print("\n" + "="*70)
    print("ğŸ’¡ CONCEITOS APRENDIDOS:")
    print("="*70)
    print("""
1. âœ… Task Queue: Processar trabalho em background
2. âœ… Retry Strategy: Exponential backoff para resiliÃªncia
3. âœ… IdempotÃªncia: Executar mÃºltiplas vezes = mesmo resultado
4. âœ… Chain: Encadear tasks (output â†’ input)
5. âœ… Group: Executar tasks em paralelo
6. âœ… Chord: Paralelo + callback
7. âœ… Dead Letter Queue: Analisar falhas permanentes
8. âœ… Fanout: Broadcast para mÃºltiplos consumers
9. âœ… Saga Pattern: TransaÃ§Ã£o distribuÃ­da com compensaÃ§Ã£o
10. âœ… Monitoring: Rastrear saÃºde das filas

ğŸ“š QUANDO USAR FILAS:
- âœ… Processar trabalho demorado sem bloquear requisiÃ§Ã£o HTTP
- âœ… Retry automÃ¡tico em caso de falha
- âœ… Distribuir carga entre mÃºltiplos workers
- âœ… Processar trabalho em horÃ¡rios especÃ­ficos (scheduling)
- âœ… Desacoplar serviÃ§os (microserviÃ§os)

âš ï¸  CUIDADOS:
- âŒ Tasks devem ser idempotentes (podem ser re-executadas)
- âŒ NÃ£o guardar estado em memÃ³ria (workers podem morrer)
- âŒ Monitorar tamanho das filas (backlog)
- âŒ Implementar timeout para evitar tasks travadas
- âŒ Ter DLQ para anÃ¡lise de falhas permanentes
""")

# üöó Projeto 8: Uber/Lyft (System Design)

> Location-based matching - aparece em 85% das entrevistas de big tech

---

## üìã Problema

**Descri√ß√£o:** Design de sistema de ride-sharing escal√°vel para 100M usu√°rios.

**Requisitos Funcionais:**
1. ‚úÖ Passageiro solicita corrida
2. ‚úÖ Matching autom√°tico com motorista pr√≥ximo
3. ‚úÖ Tracking em tempo real (GPS)
4. ‚úÖ C√°lculo de ETA e pre√ßo din√¢mico (surge pricing)
5. ‚úÖ Hist√≥rico de corridas
6. ‚úÖ Avalia√ß√µes (ratings)
7. ‚úÖ Pagamento integrado

**Requisitos N√£o-Funcionais:**
1. üìä **Escala**: 100M usu√°rios, 10M corridas/dia
2. ‚ö° **Lat√™ncia**: Matching <5s, Location updates <1s
3. üí™ **Disponibilidade**: 99.99% uptime (SLA cr√≠tico!)
4. üîÑ **Consist√™ncia**: Strong consistency para matching
5. üìç **Precis√£o**: GPS accuracy <10 metros

**Estimativas de Escala:**
```
Usu√°rios: 100M total, 10M ativos/dia
Motoristas: 5M total, 1M ativos/dia
Corridas: 10M/dia = 115 corridas/segundo

Picos (rush hour): 3x m√©dia = 345 corridas/segundo

Location updates:
- 1M motoristas ativos * 1 update/3s = 333k updates/segundo
- 10M passageiros tracking * 1 update/5s = 2M updates/segundo
- Total: ~2.3M location updates/segundo (MASSIVO!)

Storage:
- Corridas: 10M/dia * 365 * 5 anos * 1KB = 18TB
- Location history: 2.3M/s * 3600*24 * 100 bytes = 19TB/dia (!)
  ‚Üí Comprimir e archive para S3 ap√≥s 30 dias

Bandwidth:
- Location updates: 2.3M/s * 100 bytes = 230 MB/s uplink
- Tracking: 10M clientes * 10 updates/s * 100 bytes = 10 GB/s downlink (!)
```

---

## üèóÔ∏è High-Level Architecture

```
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   Cliente   ‚îÇ
                       ‚îÇ (App Mobile)‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                          HTTPS/WSS
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                             ‚îÇ                             ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ         ‚îÇ  Load Balancer (NGINX/ALB)       ‚îÇ             ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                             ‚îÇ                             ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ         ‚îÇ                                   ‚îÇ             ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ   ‚îÇ   API      ‚îÇ  ‚îÇ  WebSocket ‚îÇ  ‚îÇ  Location      ‚îÇ    ‚îÇ
‚îÇ   ‚îÇ  Gateway   ‚îÇ  ‚îÇ   Server   ‚îÇ  ‚îÇ   Service      ‚îÇ    ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ         ‚îÇ               ‚îÇ                  ‚îÇ             ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                         ‚îÇ                                ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ    ‚îÇ                    ‚îÇ                    ‚îÇ          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ   User     ‚îÇ  ‚îÇ   Matching  ‚îÇ  ‚îÇ    Pricing     ‚îÇ   ‚îÇ
‚îÇ ‚îÇ  Service   ‚îÇ  ‚îÇ   Service   ‚îÇ  ‚îÇ    Service     ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ    ‚îÇ                   ‚îÇ                    ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                   ‚îÇ                    ‚îÇ
     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA LAYER                         ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL  ‚îÇ  ‚îÇ    Redis     ‚îÇ  ‚îÇ  Kafka     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ (Users/Rides)‚îÇ  ‚îÇ   (Cache)    ‚îÇ  ‚îÇ (Events)   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Geohash    ‚îÇ  ‚îÇ  TimeSeries  ‚îÇ  ‚îÇ     S3     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Index (Redis)‚îÇ  ‚îÇ  DB (Influx) ‚îÇ  ‚îÇ  (Archive) ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

EXTERNAL SERVICES:
  - Google Maps API (ETA, routing)
  - Stripe/Payment Gateway
  - Twilio (SMS notifications)
  - Firebase (Push notifications)
```

---

## üóÑÔ∏è Database Design

### 1. Schema SQL (PostgreSQL)

```sql
-- Usu√°rios
CREATE TABLE users (
    id BIGSERIAL PRIMARY KEY,
    phone VARCHAR(20) UNIQUE NOT NULL,
    email VARCHAR(255),
    name VARCHAR(100),
    user_type VARCHAR(20) NOT NULL, -- 'rider' ou 'driver'
    rating DECIMAL(3,2) DEFAULT 5.0,
    total_rides INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_phone (phone),
    INDEX idx_user_type (user_type)
);

-- Motoristas (estende users)
CREATE TABLE drivers (
    user_id BIGINT PRIMARY KEY REFERENCES users(id),
    vehicle_type VARCHAR(50), -- 'UberX', 'UberXL', 'Uber Black'
    vehicle_model VARCHAR(100),
    license_plate VARCHAR(20),
    documents_verified BOOLEAN DEFAULT FALSE,
    status VARCHAR(20) DEFAULT 'offline', -- 'offline', 'online', 'busy'
    current_lat DECIMAL(10,8),
    current_lng DECIMAL(11,8),
    last_location_update TIMESTAMP,
    INDEX idx_status (status),
    INDEX idx_location (current_lat, current_lng)
);

-- Corridas
CREATE TABLE rides (
    id BIGSERIAL PRIMARY KEY,
    rider_id BIGINT NOT NULL REFERENCES users(id),
    driver_id BIGINT REFERENCES users(id),

    -- Localiza√ß√£o
    pickup_lat DECIMAL(10,8) NOT NULL,
    pickup_lng DECIMAL(11,8) NOT NULL,
    pickup_address TEXT,
    dropoff_lat DECIMAL(10,8),
    dropoff_lng DECIMAL(11,8),
    dropoff_address TEXT,

    -- Status
    status VARCHAR(20) NOT NULL, -- 'requested', 'matched', 'arrived', 'started', 'completed', 'cancelled'

    -- Pricing
    estimated_price DECIMAL(10,2),
    final_price DECIMAL(10,2),
    surge_multiplier DECIMAL(3,2) DEFAULT 1.0,

    -- Timestamps
    requested_at TIMESTAMP DEFAULT NOW(),
    matched_at TIMESTAMP,
    arrived_at TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,

    -- Ratings
    rider_rating INTEGER CHECK (rider_rating BETWEEN 1 AND 5),
    driver_rating INTEGER CHECK (driver_rating BETWEEN 1 AND 5),

    INDEX idx_rider (rider_id),
    INDEX idx_driver (driver_id),
    INDEX idx_status (status),
    INDEX idx_requested_at (requested_at)
);

-- Location history (particionada por tempo)
CREATE TABLE location_history (
    id BIGSERIAL,
    user_id BIGINT NOT NULL,
    lat DECIMAL(10,8) NOT NULL,
    lng DECIMAL(11,8) NOT NULL,
    timestamp TIMESTAMP NOT NULL DEFAULT NOW(),
    PRIMARY KEY (id, timestamp)
) PARTITION BY RANGE (timestamp);

-- Parti√ß√µes mensais
CREATE TABLE location_history_2024_01 PARTITION OF location_history
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE location_history_2024_02 PARTITION OF location_history
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
-- ...
```

---

## üåç Geospatial Indexing (CR√çTICO!)

### Problema: Encontrar motoristas pr√≥ximos R√ÅPIDO

**Abordagem Ing√™nua (ERRADA):**
```sql
-- ‚ùå HORR√çVEL: Escaneia TODOS motoristas
SELECT * FROM drivers
WHERE status = 'online'
  AND SQRT(POW(current_lat - ?, 2) + POW(current_lng - ?, 2)) < 0.01
ORDER BY distance
LIMIT 10;

-- Complexidade: O(N) onde N = todos motoristas
-- Com 1M motoristas: ~500ms (INACEIT√ÅVEL!)
```

### Solu√ß√£o 1: Geohash (RECOMENDADO)

```python
import geohash2

class GeohashIndex:
    """
    Geohash: Divide mundo em grid hier√°rquico

    Exemplo:
    geohash("37.7749, -122.4194", precision=6) ‚Üí "9q8yy"

    Precision:
    1 = ¬±2500km (continente)
    2 = ¬±630km  (estado)
    3 = ¬±78km   (cidade)
    4 = ¬±20km
    5 = ¬±2.4km
    6 = ¬±610m   ‚Üê IDEAL para Uber
    7 = ¬±76m
    8 = ¬±19m
    """

    def __init__(self, redis_client):
        self.redis = redis_client
        self.precision = 6  # ~610m per cell

    def index_driver(self, driver_id: int, lat: float, lng: float):
        """
        Indexar motorista no geohash

        Redis: geohash:{hash} ‚Üí Set[driver_id]
        """
        gh = geohash2.encode(lat, lng, precision=self.precision)
        key = f"geohash:{gh}"

        # Adicionar ao set
        self.redis.sadd(key, driver_id)

        # TTL de 5 minutos (motorista precisa enviar location update)
        self.redis.expire(key, 300)

        # Salvar metadata do motorista
        self.redis.setex(
            f"driver:{driver_id}:location",
            300,
            f"{lat},{lng}"
        )

    def find_nearby_drivers(
        self,
        lat: float,
        lng: float,
        radius_km: float = 5,
        limit: int = 10
    ) -> List[int]:
        """
        Buscar motoristas pr√≥ximos

        Algoritmo:
        1. Calcular geohash do rider
        2. Buscar na c√©lula atual + 8 c√©lulas vizinhas
        3. Filtrar por dist√¢ncia real (Haversine)
        4. Ordenar por dist√¢ncia
        """
        gh_center = geohash2.encode(lat, lng, precision=self.precision)

        # Buscar c√©lula atual + vizinhos
        geohashes_to_check = [gh_center] + geohash2.neighbors(gh_center)

        driver_ids = set()

        for gh in geohashes_to_check:
            key = f"geohash:{gh}"
            ids = self.redis.smembers(key)
            driver_ids.update([int(id_) for id_ in ids])

        # Filtrar por dist√¢ncia real
        nearby_drivers = []

        for driver_id in driver_ids:
            location = self.redis.get(f"driver:{driver_id}:location")

            if not location:
                continue

            driver_lat, driver_lng = map(float, location.decode().split(','))

            distance = haversine_distance(lat, lng, driver_lat, driver_lng)

            if distance <= radius_km:
                nearby_drivers.append({
                    'driver_id': driver_id,
                    'distance_km': distance,
                    'lat': driver_lat,
                    'lng': driver_lng
                })

        # Ordenar por dist√¢ncia
        nearby_drivers.sort(key=lambda d: d['distance_km'])

        return nearby_drivers[:limit]

    def remove_driver(self, driver_id: int, lat: float, lng: float):
        """Remover motorista (quando vai offline ou aceita corrida)"""
        gh = geohash2.encode(lat, lng, precision=self.precision)
        key = f"geohash:{gh}"

        self.redis.srem(key, driver_id)
        self.redis.delete(f"driver:{driver_id}:location")


def haversine_distance(lat1: float, lng1: float, lat2: float, lng2: float) -> float:
    """
    Calcular dist√¢ncia entre 2 pontos (Haversine formula)

    Retorna: dist√¢ncia em KM
    """
    from math import radians, sin, cos, sqrt, atan2

    R = 6371  # Raio da Terra em km

    lat1, lng1, lat2, lng2 = map(radians, [lat1, lng1, lat2, lng2])

    dlat = lat2 - lat1
    dlng = lng2 - lng1

    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlng/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))

    return R * c
```

**Complexidade:**
- Indexar: O(1)
- Buscar: O(9 * k) onde k = motoristas por c√©lula (~10-50)
- **Total: O(1) na pr√°tica!**

**Benchmark:**
```
1M motoristas online
Query radius: 5km

Geohash: 5-10ms ‚úÖ
Brute force: 500ms ‚ùå

Speedup: 50-100x!
```

### Solu√ß√£o 2: Redis GEO (Alternativa Simples)

```python
class RedisGeoIndex:
    """
    Redis GEO commands (usa Geohash internamente)

    Mais simples mas menos flex√≠vel
    """

    def __init__(self, redis_client):
        self.redis = redis_client

    def index_driver(self, driver_id: int, lat: float, lng: float):
        """Adicionar motorista"""
        self.redis.geoadd('drivers:online', lng, lat, driver_id)
        # Nota: Redis GEO usa (lng, lat) n√£o (lat, lng)!

    def find_nearby_drivers(
        self,
        lat: float,
        lng: float,
        radius_km: float = 5,
        limit: int = 10
    ):
        """Buscar motoristas pr√≥ximos"""
        results = self.redis.georadius(
            'drivers:online',
            lng, lat,
            radius_km,
            unit='km',
            withdist=True,  # Incluir dist√¢ncia
            sort='ASC',     # Ordenar por dist√¢ncia
            count=limit
        )

        nearby = [
            {
                'driver_id': int(driver_id),
                'distance_km': float(distance)
            }
            for driver_id, distance in results
        ]

        return nearby

    def remove_driver(self, driver_id: int):
        """Remover motorista"""
        self.redis.zrem('drivers:online', driver_id)
```

**Quando usar cada:**
- **Geohash manual**: Mais controle, suporta sharding complexo
- **Redis GEO**: Simples, suficiente para 80% dos casos

---

## üéØ Core Features

### 1. Solicitar Corrida (Ride Request)

```python
from fastapi import FastAPI, WebSocket, HTTPException
from pydantic import BaseModel
import uuid

app = FastAPI()

class RideRequest(BaseModel):
    rider_id: int
    pickup_lat: float
    pickup_lng: float
    dropoff_lat: float
    dropoff_lng: float


@app.post("/rides/request")
async def request_ride(request: RideRequest):
    """
    Solicitar corrida

    Workflow:
    1. Validar request
    2. Calcular pre√ßo estimado
    3. Buscar motoristas pr√≥ximos
    4. Criar ride no DB (status='requested')
    5. Enviar matching request ass√≠ncrono
    """
    # 1. Validar
    rider = get_user(request.rider_id)

    if not rider or rider.user_type != 'rider':
        raise HTTPException(400, "Invalid rider")

    # 2. Calcular pre√ßo estimado (ver se√ß√£o Pricing)
    estimated_price, surge_multiplier = calculate_price(
        pickup_lat=request.pickup_lat,
        pickup_lng=request.pickup_lng,
        dropoff_lat=request.dropoff_lat,
        dropoff_lng=request.dropoff_lng
    )

    # 3. Buscar motoristas pr√≥ximos
    geo_index = GeohashIndex(redis_client)

    nearby_drivers = geo_index.find_nearby_drivers(
        lat=request.pickup_lat,
        lng=request.pickup_lng,
        radius_km=5,
        limit=20
    )

    if not nearby_drivers:
        raise HTTPException(404, "No drivers available nearby")

    # 4. Criar ride
    ride_id = create_ride(
        rider_id=request.rider_id,
        pickup_lat=request.pickup_lat,
        pickup_lng=request.pickup_lng,
        dropoff_lat=request.dropoff_lat,
        dropoff_lng=request.dropoff_lng,
        estimated_price=estimated_price,
        surge_multiplier=surge_multiplier,
        status='requested'
    )

    # 5. Matching ass√≠ncrono (Kafka)
    kafka_producer.send('ride_matching', {
        'ride_id': ride_id,
        'rider_id': request.rider_id,
        'pickup_lat': request.pickup_lat,
        'pickup_lng': request.pickup_lng,
        'nearby_drivers': [d['driver_id'] for d in nearby_drivers]
    })

    return {
        'ride_id': ride_id,
        'estimated_price': estimated_price,
        'surge_multiplier': surge_multiplier,
        'status': 'searching_for_driver'
    }
```

### 2. Matching Algorithm

```python
import time
from typing import Optional

def matching_worker():
    """
    Worker de matching (Kafka Consumer)

    Algoritmo:
    1. Receber ride request
    2. Tentar match com motoristas pr√≥ximos (em ordem de dist√¢ncia)
    3. Enviar notifica√ß√£o para motorista via push
    4. Esperar 15s por aceita√ß√£o
    5. Se timeout, tentar pr√≥ximo motorista
    6. Repetir at√© match ou timeout total (2 minutos)
    """
    from kafka import KafkaConsumer

    consumer = KafkaConsumer('ride_matching', bootstrap_servers=['kafka:9092'])

    for message in consumer:
        data = message.value

        ride_id = data['ride_id']
        rider_id = data['rider_id']
        nearby_drivers = data['nearby_drivers']

        # Tentar match
        matched = try_match_ride(ride_id, nearby_drivers)

        if not matched:
            # Nenhum motorista aceitou
            update_ride_status(ride_id, 'no_drivers_available')
            notify_rider(rider_id, 'No drivers available, please try again')


def try_match_ride(ride_id: int, nearby_drivers: List[int]) -> bool:
    """
    Tentar match com motoristas

    Retorna True se matched, False se timeout
    """
    MAX_ATTEMPTS = 5
    TIMEOUT_PER_DRIVER = 15  # segundos

    for i, driver_id in enumerate(nearby_drivers[:MAX_ATTEMPTS]):
        # Verificar se motorista ainda est√° online
        driver_status = redis_client.get(f"driver:{driver_id}:status")

        if driver_status != b'online':
            continue  # Pular

        # Lock: Garantir que motorista n√£o receba m√∫ltiplos requests
        lock_key = f"driver_lock:{driver_id}"
        acquired = redis_client.set(lock_key, ride_id, nx=True, ex=TIMEOUT_PER_DRIVER)

        if not acquired:
            continue  # Motorista j√° tem request pendente

        # Enviar notifica√ß√£o para motorista
        send_push_notification(
            driver_id,
            title="New ride request!",
            body="Pickup in 5 minutes",
            data={
                'ride_id': ride_id,
                'pickup_lat': '...',
                'pickup_lng': '...'
            }
        )

        # Marcar como pending
        redis_client.setex(
            f"ride:{ride_id}:pending_driver",
            TIMEOUT_PER_DRIVER,
            driver_id
        )

        # Esperar aceita√ß√£o (com timeout)
        start_time = time.time()

        while time.time() - start_time < TIMEOUT_PER_DRIVER:
            # Verificar se motorista aceitou
            accepted = redis_client.get(f"ride:{ride_id}:accepted")

            if accepted:
                # Match sucesso!
                finalize_match(ride_id, driver_id)
                return True

            time.sleep(0.5)

        # Timeout, liberar lock e tentar pr√≥ximo
        redis_client.delete(lock_key)

    # Nenhum motorista aceitou
    return False


@app.post("/rides/{ride_id}/accept")
async def accept_ride(ride_id: int, driver_id: int):
    """
    Motorista aceitar corrida

    Opera√ß√µes at√¥micas para evitar double-booking
    """
    # Verificar se request ainda est√° pending para esse motorista
    pending_driver = redis_client.get(f"ride:{ride_id}:pending_driver")

    if not pending_driver or int(pending_driver) != driver_id:
        raise HTTPException(400, "Ride request expired or already accepted")

    # At√¥mico: Marcar como accepted (CAS)
    accepted = redis_client.set(
        f"ride:{ride_id}:accepted",
        driver_id,
        nx=True,  # Apenas se n√£o existir
        ex=60
    )

    if not accepted:
        raise HTTPException(409, "Ride already accepted by another driver")

    # Finalizar match
    finalize_match(ride_id, driver_id)

    return {"status": "accepted", "ride_id": ride_id}


def finalize_match(ride_id: int, driver_id: int):
    """
    Finalizar match (atualizar DB, notificar, etc)
    """
    # Atualizar DB
    db.execute("""
        UPDATE rides
        SET driver_id = ?, status = 'matched', matched_at = NOW()
        WHERE id = ?
    """, (driver_id, ride_id))

    # Atualizar status do motorista
    db.execute("""
        UPDATE drivers
        SET status = 'busy'
        WHERE user_id = ?
    """, (driver_id,))

    # Remover motorista do geohash index
    driver_location = get_driver_location(driver_id)
    geo_index.remove_driver(driver_id, driver_location['lat'], driver_location['lng'])

    # Notificar rider
    ride = get_ride(ride_id)
    notify_rider(
        ride.rider_id,
        f"Driver matched! ETA: 5 minutes",
        data={'driver_id': driver_id, 'ride_id': ride_id}
    )

    # Notificar driver
    notify_driver(
        driver_id,
        f"Ride confirmed! Navigate to pickup location",
        data={'ride_id': ride_id}
    )
```

### 3. Real-Time Tracking (WebSocket)

```python
from typing import Dict
import json

class TrackingManager:
    """Gerenciar tracking de corridas"""

    def __init__(self):
        # ride_id -> Set[WebSocket]
        self.active_rides: Dict[int, set] = {}

    async def connect(self, websocket: WebSocket, ride_id: int):
        """Conectar cliente (rider ou driver) ao tracking"""
        await websocket.accept()

        if ride_id not in self.active_rides:
            self.active_rides[ride_id] = set()

        self.active_rides[ride_id].add(websocket)

    async def disconnect(self, websocket: WebSocket, ride_id: int):
        """Desconectar"""
        if ride_id in self.active_rides:
            self.active_rides[ride_id].discard(websocket)

    async def broadcast_location(self, ride_id: int, location: dict):
        """Broadcast location update para todos conectados √† corrida"""
        if ride_id not in self.active_rides:
            return

        disconnected = set()

        for websocket in self.active_rides[ride_id]:
            try:
                await websocket.send_json(location)
            except:
                disconnected.add(websocket)

        # Limpar conex√µes mortas
        self.active_rides[ride_id] -= disconnected


tracking_manager = TrackingManager()


@app.websocket("/rides/{ride_id}/track")
async def track_ride(websocket: WebSocket, ride_id: int):
    """
    WebSocket para tracking em tempo real

    Cliente recebe location updates do motorista
    """
    await tracking_manager.connect(websocket, ride_id)

    try:
        while True:
            # Heartbeat (manter conex√£o viva)
            await websocket.receive_text()
    except:
        await tracking_manager.disconnect(websocket, ride_id)


@app.post("/drivers/location")
async def update_driver_location(
    driver_id: int,
    lat: float,
    lng: float
):
    """
    Motorista enviar location update (a cada 3-5 segundos)

    Atualiza:
    1. Geohash index (para matching)
    2. Current ride tracking (se em corrida)
    3. Location history (para analytics)
    """
    # 1. Atualizar geohash index
    driver = get_driver(driver_id)

    if driver.status == 'online':
        geo_index.index_driver(driver_id, lat, lng)

    # 2. Se em corrida, broadcast para tracking
    current_ride = get_driver_current_ride(driver_id)

    if current_ride:
        await tracking_manager.broadcast_location(
            current_ride.id,
            {
                'driver_lat': lat,
                'driver_lng': lng,
                'timestamp': time.time()
            }
        )

    # 3. Salvar location history (ass√≠ncrono)
    kafka_producer.send('location_history', {
        'user_id': driver_id,
        'lat': lat,
        'lng': lng,
        'timestamp': time.time()
    })

    return {"status": "ok"}
```

### 4. Dynamic Pricing (Surge Pricing)

```python
def calculate_price(
    pickup_lat: float,
    pickup_lng: float,
    dropoff_lat: float,
    dropoff_lng: float
) -> tuple[float, float]:
    """
    Calcular pre√ßo din√¢mico

    Fatores:
    1. Dist√¢ncia (Google Maps API)
    2. Tempo estimado (ETA)
    3. Demanda vs Oferta (surge multiplier)
    4. Hor√°rio (rush hour +20%)
    5. Clima (chuva +30%)
    """
    # 1. Calcular dist√¢ncia e tempo
    distance_km, duration_min = get_route_info(
        pickup_lat, pickup_lng,
        dropoff_lat, dropoff_lng
    )

    # 2. Pre√ßo base
    BASE_FARE = 5.00  # USD
    PER_KM = 2.00
    PER_MIN = 0.50

    base_price = BASE_FARE + (distance_km * PER_KM) + (duration_min * PER_MIN)

    # 3. Calcular surge multiplier
    surge_multiplier = calculate_surge_multiplier(pickup_lat, pickup_lng)

    # 4. Ajustes adicionais
    hour = datetime.now().hour

    # Rush hour (7-9am, 5-7pm)
    if hour in [7, 8, 17, 18]:
        surge_multiplier *= 1.2

    # Clima (verificar API)
    if is_raining(pickup_lat, pickup_lng):
        surge_multiplier *= 1.3

    # 5. Pre√ßo final
    final_price = base_price * surge_multiplier

    # Min/max
    final_price = max(final_price, 8.00)  # M√≠nimo $8
    final_price = min(final_price, 500.00)  # M√°ximo $500

    return round(final_price, 2), round(surge_multiplier, 2)


def calculate_surge_multiplier(lat: float, lng: float) -> float:
    """
    Calcular surge baseado em demanda/oferta

    Surge = Demand / Supply

    Usa geohash para agregar m√©tricas por regi√£o
    """
    gh = geohash2.encode(lat, lng, precision=5)  # ~2.4km cell

    # Contar rides requested (√∫ltimos 10 minutos)
    demand_key = f"demand:{gh}"
    demand = int(redis_client.get(demand_key) or 0)

    # Contar drivers online
    supply = len(geo_index.find_nearby_drivers(lat, lng, radius_km=3))

    if supply == 0:
        return 2.0  # Surge m√°ximo

    # F√≥rmula surge
    ratio = demand / supply

    if ratio < 1.0:
        return 1.0  # Sem surge
    elif ratio < 2.0:
        return 1.5
    elif ratio < 3.0:
        return 2.0
    else:
        return 2.5  # Surge m√°ximo


# Worker para atualizar m√©tricas de demanda
def demand_tracking_worker():
    """
    Consumir ride requests e incrementar contador de demanda por regi√£o
    """
    consumer = KafkaConsumer('ride_matching', bootstrap_servers=['kafka:9092'])

    for message in consumer:
        data = message.value

        lat = data['pickup_lat']
        lng = data['pickup_lng']

        gh = geohash2.encode(lat, lng, precision=5)
        demand_key = f"demand:{gh}"

        # Incrementar (TTL 10 minutos)
        redis_client.incr(demand_key)
        redis_client.expire(demand_key, 600)
```

---

## üéØ Perguntas da Entrevista

**Interviewer:** "Como voc√™ garante que 2 motoristas n√£o aceitam a mesma corrida?"

**Voc√™:** "Distributed lock com Redis:
1. Quando matching tenta driver, adquire lock: `SET driver_lock:{driver_id} {ride_id} NX EX 15`
2. Quando motorista aceita, usa CAS (Compare-And-Set): `SET ride:{ride_id}:accepted {driver_id} NX`
3. Se CAS falha = outro motorista j√° aceitou (409 Conflict)
4. Lock expira em 15s se motorista n√£o responde"

---

**Interviewer:** "Como escalar location updates (2M/segundo)?"

**Voc√™:** "Estrat√©gias:
1. **Batch updates**: Cliente envia 3-5 locations de uma vez (reduz HTTP overhead)
2. **Adaptive rate**: Se motorista parado, reduzir rate (1 update/10s). Se em movimento, aumentar (1 update/3s)
3. **UDP ao inv√©s de HTTP**: Para location updates (tolerar packet loss)
4. **Sharding**: Particionar motoristas por geohash prefix (SF=9q8, NYC=dr5)
5. **Sampling**: Archive apenas 1 em 10 locations para history (analytics n√£o precisa de todas)"

---

**Interviewer:** "Geohash vs Quadtree, qual √© melhor?"

**Voc√™:** "Depende:

**Geohash**: ‚úÖ Simples, ‚úÖ Funciona em Redis, ‚ö†Ô∏è C√©lulas fixas (pode ter hotspots em √°reas densas)

**Quadtree**: ‚úÖ Adaptativo (subdivide c√©lulas densas), ‚ùå Complexo de implementar, ‚ùå N√£o tem suporte nativo em Redis

Para Uber: Geohash √© suficiente. Quadtree s√≥ vale se tiver hotspots extremos (ex: Times Square no NYE)"

---

## ‚úÖ Checklist da Entrevista

- [ ] Estimar escala (QPS, location updates, storage)
- [ ] Desenhar arquitetura high-level
- [ ] Explicar geospatial indexing (Geohash)
- [ ] Implementar matching algorithm
- [ ] Real-time tracking (WebSocket)
- [ ] Dynamic pricing (surge)
- [ ] Concorr√™ncia (distributed locks)
- [ ] Sharding strategy
- [ ] Otimiza√ß√µes (caching, batching)

---

**System design extremamente comum em entrevistas! üöó**

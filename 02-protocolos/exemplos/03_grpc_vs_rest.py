"""
MÃ³dulo 02 - Protocolos: gRPC vs REST Comparison

Este exemplo demonstra:
1. ImplementaÃ§Ã£o REST tradicional (JSON/HTTP)
2. ImplementaÃ§Ã£o gRPC (Protocol Buffers/HTTP2)
3. Performance comparison
4. Quando usar cada um

Instalar dependÃªncias:
    pip install grpcio grpcio-tools fastapi uvicorn httpx

Gerar cÃ³digo gRPC:
    python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. user_service.proto

Execute:
    # Terminal 1: REST server
    uvicorn 03_grpc_vs_rest:rest_app --port 8000

    # Terminal 2: gRPC server
    python 03_grpc_vs_rest.py --mode grpc-server

    # Terminal 3: Benchmark
    python 03_grpc_vs_rest.py --mode benchmark
"""

import time
import asyncio
import logging
from typing import List, Optional
from dataclasses import dataclass
from concurrent import futures
import sys

# REST imports
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import httpx

# gRPC imports (commented out se nÃ£o tiver instalado)
# import grpc
# from generated import user_service_pb2, user_service_pb2_grpc

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)


# ============================================================================
# DEFINIÃ‡ÃƒO DO PROTOCOLO gRPC (user_service.proto)
# ============================================================================

"""
// user_service.proto

syntax = "proto3";

package user;

service UserService {
  rpc GetUser(GetUserRequest) returns (User);
  rpc ListUsers(ListUsersRequest) returns (UserList);
  rpc CreateUser(CreateUserRequest) returns (User);
  rpc StreamUsers(StreamUsersRequest) returns (stream User);  // Server streaming
  rpc BulkCreateUsers(stream CreateUserRequest) returns (CreateUsersResponse);  // Client streaming
}

message User {
  int32 id = 1;
  string username = 2;
  string email = 3;
  int32 age = 4;
  bool is_active = 5;
}

message GetUserRequest {
  int32 id = 1;
}

message ListUsersRequest {
  int32 limit = 1;
  int32 offset = 2;
}

message UserList {
  repeated User users = 1;
  int32 total = 2;
}

message CreateUserRequest {
  string username = 1;
  string email = 2;
  int32 age = 3;
}

message StreamUsersRequest {
  int32 batch_size = 1;
}

message CreateUsersResponse {
  int32 created_count = 1;
}
"""


# ============================================================================
# MOCK DATABASE
# ============================================================================

@dataclass
class User:
    id: int
    username: str
    email: str
    age: int
    is_active: bool


# Database simulado
USERS_DB = [
    User(i, f"user{i}", f"user{i}@example.com", 20 + i, True)
    for i in range(1, 1001)  # 1000 usuÃ¡rios
]


def get_user(user_id: int) -> Optional[User]:
    """Buscar usuÃ¡rio por ID"""
    for user in USERS_DB:
        if user.id == user_id:
            return user
    return None


def list_users(limit: int = 10, offset: int = 0) -> List[User]:
    """Listar usuÃ¡rios com paginaÃ§Ã£o"""
    return USERS_DB[offset:offset + limit]


def create_user(username: str, email: str, age: int) -> User:
    """Criar novo usuÃ¡rio"""
    new_id = len(USERS_DB) + 1
    user = User(new_id, username, email, age, True)
    USERS_DB.append(user)
    return user


# ============================================================================
# IMPLEMENTAÃ‡ÃƒO REST (FastAPI)
# ============================================================================

rest_app = FastAPI(title="REST User Service")


# Schemas Pydantic
class UserResponse(BaseModel):
    id: int
    username: str
    email: str
    age: int
    is_active: bool

    class Config:
        from_attributes = True


class UserListResponse(BaseModel):
    users: List[UserResponse]
    total: int


class CreateUserRequest(BaseModel):
    username: str
    email: str
    age: int


# Endpoints REST
@rest_app.get("/users/{user_id}", response_model=UserResponse)
def get_user_rest(user_id: int):
    """GET /users/{id} - Buscar usuÃ¡rio"""
    user = get_user(user_id)
    if not user:
        raise HTTPException(404, "User not found")
    return user


@rest_app.get("/users", response_model=UserListResponse)
def list_users_rest(limit: int = 10, offset: int = 0):
    """GET /users?limit=10&offset=0 - Listar usuÃ¡rios"""
    users = list_users(limit, offset)
    return {
        "users": users,
        "total": len(USERS_DB)
    }


@rest_app.post("/users", response_model=UserResponse, status_code=201)
def create_user_rest(request: CreateUserRequest):
    """POST /users - Criar usuÃ¡rio"""
    user = create_user(request.username, request.email, request.age)
    return user


# ============================================================================
# IMPLEMENTAÃ‡ÃƒO gRPC
# ============================================================================

# Nota: CÃ³digo gRPC comentado pois requer compilar .proto
# Descomentar apÃ³s gerar cÃ³digo com protoc

"""
class UserServiceServicer(user_service_pb2_grpc.UserServiceServicer):
    '''ImplementaÃ§Ã£o do serviÃ§o gRPC'''

    def GetUser(self, request, context):
        '''Buscar usuÃ¡rio'''
        user = get_user(request.id)
        if not user:
            context.set_code(grpc.StatusCode.NOT_FOUND)
            context.set_details('User not found')
            return user_service_pb2.User()

        return user_service_pb2.User(
            id=user.id,
            username=user.username,
            email=user.email,
            age=user.age,
            is_active=user.is_active
        )

    def ListUsers(self, request, context):
        '''Listar usuÃ¡rios'''
        users = list_users(request.limit, request.offset)

        user_messages = [
            user_service_pb2.User(
                id=u.id,
                username=u.username,
                email=u.email,
                age=u.age,
                is_active=u.is_active
            )
            for u in users
        ]

        return user_service_pb2.UserList(
            users=user_messages,
            total=len(USERS_DB)
        )

    def CreateUser(self, request, context):
        '''Criar usuÃ¡rio'''
        user = create_user(request.username, request.email, request.age)

        return user_service_pb2.User(
            id=user.id,
            username=user.username,
            email=user.email,
            age=user.age,
            is_active=user.is_active
        )

    def StreamUsers(self, request, context):
        '''Server streaming: enviar usuÃ¡rios em stream'''
        batch_size = request.batch_size or 10

        for i in range(0, len(USERS_DB), batch_size):
            batch = USERS_DB[i:i + batch_size]

            for user in batch:
                yield user_service_pb2.User(
                    id=user.id,
                    username=user.username,
                    email=user.email,
                    age=user.age,
                    is_active=user.is_active
                )

            time.sleep(0.1)  # Simular processamento

    def BulkCreateUsers(self, request_iterator, context):
        '''Client streaming: receber mÃºltiplos usuÃ¡rios para criar'''
        count = 0

        for request in request_iterator:
            create_user(request.username, request.email, request.age)
            count += 1

        return user_service_pb2.CreateUsersResponse(created_count=count)


def serve_grpc():
    '''Iniciar servidor gRPC'''
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))

    user_service_pb2_grpc.add_UserServiceServicer_to_server(
        UserServiceServicer(), server
    )

    server.add_insecure_port('[::]:50051')
    server.start()

    logger.info('gRPC server started on port 50051')
    server.wait_for_termination()
"""


# ============================================================================
# BENCHMARK: REST vs gRPC
# ============================================================================

async def benchmark_rest():
    """Benchmark REST API"""
    logger.info("ğŸš€ Benchmarking REST...")

    async with httpx.AsyncClient(base_url="http://localhost:8000") as client:
        # Teste 1: Get single user (100x)
        start = time.time()
        tasks = [client.get(f"/users/{i}") for i in range(1, 101)]
        responses = await asyncio.gather(*tasks)
        elapsed = time.time() - start

        logger.info(f"  GET single user (100x): {elapsed:.3f}s ({100/elapsed:.0f} req/s)")

        # Teste 2: List users (50x)
        start = time.time()
        tasks = [client.get("/users?limit=20") for _ in range(50)]
        responses = await asyncio.gather(*tasks)
        elapsed = time.time() - start

        logger.info(f"  GET list users (50x): {elapsed:.3f}s ({50/elapsed:.0f} req/s)")

        # Teste 3: Create user (100x)
        start = time.time()
        tasks = [
            client.post("/users", json={
                "username": f"newuser{i}",
                "email": f"newuser{i}@example.com",
                "age": 25
            })
            for i in range(100)
        ]
        responses = await asyncio.gather(*tasks)
        elapsed = time.time() - start

        logger.info(f"  POST create user (100x): {elapsed:.3f}s ({100/elapsed:.0f} req/s)")

    return elapsed


async def benchmark_grpc():
    """Benchmark gRPC API"""
    logger.info("âš¡ Benchmarking gRPC...")

    # CÃ³digo comentado pois requer .proto compilado
    """
    channel = grpc.aio.insecure_channel('localhost:50051')
    stub = user_service_pb2_grpc.UserServiceStub(channel)

    # Teste 1: Get single user (100x)
    start = time.time()
    tasks = [
        stub.GetUser(user_service_pb2.GetUserRequest(id=i))
        for i in range(1, 101)
    ]
    responses = await asyncio.gather(*tasks)
    elapsed = time.time() - start

    logger.info(f"  GetUser (100x): {elapsed:.3f}s ({100/elapsed:.0f} req/s)")

    # Teste 2: List users (50x)
    start = time.time()
    tasks = [
        stub.ListUsers(user_service_pb2.ListUsersRequest(limit=20, offset=0))
        for _ in range(50)
    ]
    responses = await asyncio.gather(*tasks)
    elapsed = time.time() - start

    logger.info(f"  ListUsers (50x): {elapsed:.3f}s ({50/elapsed:.0f} req/s)")

    # Teste 3: Server streaming (buscar 1000 users)
    start = time.time()
    count = 0
    async for user in stub.StreamUsers(user_service_pb2.StreamUsersRequest(batch_size=50)):
        count += 1
    elapsed = time.time() - start

    logger.info(f"  StreamUsers (1000 users): {elapsed:.3f}s ({count/elapsed:.0f} users/s)")

    await channel.close()
    """

    logger.info("  (gRPC benchmark requires compiled .proto file)")


# ============================================================================
# COMPARAÃ‡ÃƒO: REST vs gRPC
# ============================================================================

def print_comparison():
    """Imprime tabela comparativa"""
    comparison = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        REST vs gRPC COMPARISON                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aspecto            â”‚       REST        â”‚             gRPC                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Protocolo          â”‚ HTTP/1.1          â”‚ HTTP/2                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Formato de dados   â”‚ JSON (texto)      â”‚ Protocol Buffers (binÃ¡rio)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tamanho payload    â”‚ ~500 bytes        â”‚ ~200 bytes (60% menor)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LatÃªncia           â”‚ ~10-50ms          â”‚ ~1-10ms (5x mais rÃ¡pido)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Throughput         â”‚ ~1k req/s         â”‚ ~10k req/s (10x mais rÃ¡pido)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Streaming          â”‚ âŒ NÃ£o (ou SSE)   â”‚ âœ… Sim (bidirecional)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Browser support    â”‚ âœ… Universal      â”‚ âš ï¸  Requer grpc-web              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Human readable     â”‚ âœ… Sim (JSON)     â”‚ âŒ NÃ£o (binÃ¡rio)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Type safety        â”‚ âš ï¸  Runtime       â”‚ âœ… Compile time                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Code generation    â”‚ âš ï¸  Opcional      â”‚ âœ… AutomÃ¡tico (.proto)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Learning curve     â”‚ â­ FÃ¡cil          â”‚ â­â­â­ MÃ©dio                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Debugging          â”‚ âœ… FÃ¡cil (curl)   â”‚ âš ï¸  Precisa grpcurl              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Caching (HTTP)     â”‚ âœ… GET cacheable  â”‚ âŒ NÃ£o usa HTTP caching          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                            QUANDO USAR CADA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Use REST quando:

  1. API pÃºblica / externa
     - Parceiros, clientes, desenvolvedores third-party
     - Browsers (web apps)
     - DocumentaÃ§Ã£o API importante (Swagger/OpenAPI)

  2. Simplicidade Ã© importante
     - MVP, protÃ³tipo rÃ¡pido
     - Time nÃ£o familiar com gRPC
     - Debugging precisa ser fÃ¡cil (curl)

  3. HTTP caching Ã© valioso
     - GET requests cacheÃ¡veis (CDN, browser)
     - Reduz carga no servidor

  4. Flexibilidade de formato
     - JSON, XML, MessagePack, etc
     - Clients diversos (mobile, web, IoT)

  Exemplos: GitHub API, Stripe API, Twitter API


âœ… Use gRPC quando:

  1. Microservices internos
     - Service-to-service communication
     - Alta performance Ã© crÃ­tica
     - Tipo de dados bem definido

  2. Alta carga / baixa latÃªncia
     - 10k+ requests/s
     - LatÃªncia <10ms
     - Payload pequeno (economia de banda)

  3. Streaming Ã© necessÃ¡rio
     - Server streaming (feed contÃ­nuo)
     - Client streaming (upload de arquivo)
     - Bidirecional (chat, multiplayer game)

  4. Type safety Ã© importante
     - Contratos fortemente tipados (.proto)
     - GeraÃ§Ã£o automÃ¡tica de cÃ³digo
     - Menos bugs em produÃ§Ã£o

  Exemplos: Google (interno), Netflix, Square, Uber


âœ… Use AMBOS (Hybrid):

  1. Gateway pattern
     - gRPC entre microservices (backend)
     - REST para clientes externos (frontend)
     - Gateway traduz REST â†’ gRPC

  2. Casos especÃ­ficos
     - gRPC para operaÃ§Ãµes crÃ­ticas (pagamento, checkout)
     - REST para operaÃ§Ãµes simples (listar produtos)

  Exemplos: Netflix, Uber, Airbnb


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        PERFORMANCE REAL-WORLD
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Benchmark: Buscar 1000 usuÃ¡rios

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Protocolo   â”‚ LatÃªncia â”‚ Throughput â”‚ Payload Size â”‚ CPU Usage   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ REST (JSON) â”‚  250ms   â”‚  4k req/s  â”‚  500 KB      â”‚  40%        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gRPC        â”‚   50ms   â”‚ 20k req/s  â”‚  200 KB      â”‚  20%        â”‚
â”‚ (Protobuf)  â”‚  (5x)    â”‚  (5x)      â”‚  (60% menor) â”‚  (50% less) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Streaming: Enviar 1 milhÃ£o de mensagens

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Protocolo   â”‚ Tempo    â”‚ Throughput â”‚ Uso de RAM  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ REST (SSE)  â”‚  180s    â”‚  5.5k/s    â”‚  800 MB     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gRPC Stream â”‚   18s    â”‚ 55k/s      â”‚  200 MB     â”‚
â”‚             â”‚  (10x)   â”‚  (10x)     â”‚  (75% less) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                          FEATURES ESPECIAIS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

gRPC Streaming:

  1. Server Streaming
     - Servidor envia mÃºltiplas respostas
     - Exemplo: Feed de notificaÃ§Ãµes, logs em tempo real

       rpc StreamUsers(StreamUsersRequest) returns (stream User);

  2. Client Streaming
     - Cliente envia mÃºltiplas requests
     - Exemplo: Upload de arquivo, batch insert

       rpc BulkCreateUsers(stream CreateUserRequest) returns (Response);

  3. Bidirectional Streaming
     - Cliente e servidor enviam mÃºltiplas mensagens
     - Exemplo: Chat, multiplayer game

       rpc Chat(stream ChatMessage) returns (stream ChatMessage);

HTTP/2 Multiplexing:

  - REST HTTP/1.1: 1 request por TCP connection
  - gRPC HTTP/2: mÃºltiplos requests na mesma connection
  - Resultado: menos overhead, menos latÃªncia

Protocol Buffers:

  - BinÃ¡rio: 5-10x menor que JSON
  - Mais rÃ¡pido de parsear (nÃ£o precisa parse de texto)
  - Versionamento: backward/forward compatible

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(comparison)


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="gRPC vs REST Demo")
    parser.add_argument(
        "--mode",
        choices=["rest", "grpc-server", "benchmark", "comparison"],
        default="comparison",
        help="Modo de execuÃ§Ã£o"
    )

    args = parser.parse_args()

    if args.mode == "rest":
        # Rodar servidor REST (use uvicorn na linha de comando)
        import uvicorn
        uvicorn.run(rest_app, host="0.0.0.0", port=8000)

    elif args.mode == "grpc-server":
        # Rodar servidor gRPC
        logger.info("gRPC server mode (requires compiled .proto)")
        # serve_grpc()  # Descomentar apÃ³s compilar .proto

    elif args.mode == "benchmark":
        # Rodar benchmark
        asyncio.run(benchmark_rest())
        # asyncio.run(benchmark_grpc())  # Descomentar apÃ³s setup gRPC

    elif args.mode == "comparison":
        # Mostrar comparaÃ§Ã£o
        print_comparison()

    print("\n" + "="*70)
    print("ğŸ’¡ RESUMO:")
    print("="*70)
    print("""
âœ… REST: APIs pÃºblicas, simplicidade, HTTP caching
âœ… gRPC: Microservices, alta performance, streaming, type safety
âœ… Hybrid: gRPC interno + REST externo (melhor dos dois mundos)

ğŸ“š PARA APRENDER MAIS:
  - gRPC docs: https://grpc.io/docs/languages/python/
  - Protocol Buffers: https://developers.google.com/protocol-buffers
  - HTTP/2: https://developers.google.com/web/fundamentals/performance/http2
  - Netflix tech blog: https://netflixtechblog.com/

ğŸš€ PRÃ“XIMOS PASSOS:
  1. Instalar gRPC: pip install grpcio grpcio-tools
  2. Criar user_service.proto
  3. Compilar: python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. user_service.proto
  4. Rodar servidores e benchmark
""")

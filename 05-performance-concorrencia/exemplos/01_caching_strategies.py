"""
Exemplo 01: EstratÃ©gias de Caching

Implementa e compara 5 estratÃ©gias de caching:
1. Cache-Aside (Lazy Loading)
2. Read-Through
3. Write-Through
4. Write-Behind (Write-Back)
5. Refresh-Ahead

Com benchmarks e anÃ¡lise de quando usar cada uma.
"""

import time
import random
from typing import Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
from collections import OrderedDict
import json

# Simular Redis (in-memory)
cache_store = {}

# Simular Database (lento)
database = {}


def simulate_db_read(key: str) -> Optional[Any]:
    """Simular leitura do banco (100ms)."""
    time.sleep(0.1)  # 100ms de latÃªncia
    return database.get(key)


def simulate_db_write(key: str, value: Any):
    """Simular escrita no banco (150ms)."""
    time.sleep(0.15)  # 150ms de latÃªncia
    database[key] = value


def cache_get(key: str) -> Optional[Any]:
    """Simular leitura do cache (1ms)."""
    time.sleep(0.001)  # 1ms de latÃªncia
    return cache_store.get(key)


def cache_set(key: str, value: Any, ttl: int = 300):
    """Simular escrita no cache (2ms)."""
    time.sleep(0.002)  # 2ms de latÃªncia
    cache_store[key] = {
        "value": value,
        "expires_at": datetime.now() + timedelta(seconds=ttl)
    }


def cache_delete(key: str):
    """Deletar do cache."""
    cache_store.pop(key, None)


# ============================================================================
# ESTRATÃ‰GIA 1: CACHE-ASIDE (Lazy Loading)
# ============================================================================

print("=" * 70)
print("ESTRATÃ‰GIA 1: CACHE-ASIDE (LAZY LOADING)")
print("=" * 70)

"""
Fluxo de leitura:
1. App verifica cache
2. Se encontrar (cache hit) â†’ retorna
3. Se nÃ£o encontrar (cache miss) â†’ busca do DB
4. Armazena no cache
5. Retorna dados

Fluxo de escrita:
1. App escreve no DB
2. App invalida cache (delete)
3. PrÃ³xima leitura vai buscar do DB (lazy)

â”Œâ”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App â”‚         â”‚ Cache â”‚         â”‚ Database â”‚
â””â”€â”€â”¬â”€â”€â”˜         â””â”€â”€â”€â”¬â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
   â”‚                â”‚                  â”‚
   â”‚ 1. GET key     â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                  â”‚
   â”‚                â”‚                  â”‚
   â”‚ Miss âŒ        â”‚                  â”‚
   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
   â”‚                â”‚                  â”‚
   â”‚ 2. SELECT      â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                â”‚                  â”‚
   â”‚ Data           â”‚                  â”‚
   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚                â”‚                  â”‚
   â”‚ 3. SET key     â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                  â”‚
   â”‚                â”‚                  â”‚
   â”‚ 4. Return data â”‚                  â”‚

âœ… PrÃ³s:
  â€¢ Simples de implementar
  â€¢ Cache sÃ³ armazena dados usados (eficiente)
  â€¢ Tolerante a falhas do cache (sempre busca DB)

âŒ Contras:
  â€¢ Cache miss penalty (latÃªncia)
  â€¢ PossÃ­vel inconsistÃªncia (DB atualizado, cache antigo)
  â€¢ Thundering herd (muitas requests simultÃ¢neas apÃ³s miss)

ğŸ¯ Quando usar:
  â€¢ PadrÃ£o mais comum (80% dos casos)
  â€¢ Dados raramente atualizados
  â€¢ OK com eventual consistency
"""


def cache_aside_get(key: str) -> Optional[Any]:
    """Cache-Aside: Leitura."""
    # 1. Tentar cache
    cached = cache_get(key)

    if cached and cached["expires_at"] > datetime.now():
        print(f"  âœ… Cache HIT: {key}")
        return cached["value"]

    print(f"  âŒ Cache MISS: {key}")

    # 2. Buscar do DB
    value = simulate_db_read(key)

    if value is not None:
        # 3. Armazenar no cache
        cache_set(key, value)

    return value


def cache_aside_set(key: str, value: Any):
    """Cache-Aside: Escrita."""
    # 1. Escrever no DB
    simulate_db_write(key, value)

    # 2. Invalidar cache (lazy loading)
    cache_delete(key)


# DemonstraÃ§Ã£o
print("\nğŸ“Š DemonstraÃ§Ã£o Cache-Aside:\n")

# Setup: adicionar dados no DB
database["user:1"] = {"id": 1, "name": "JoÃ£o"}

# Primeira leitura (cache miss)
start = time.time()
user = cache_aside_get("user:1")
print(f"  Tempo: {(time.time() - start) * 1000:.0f}ms (cache miss)")

# Segunda leitura (cache hit)
start = time.time()
user = cache_aside_get("user:1")
print(f"  Tempo: {(time.time() - start) * 1000:.0f}ms (cache hit)")

# AtualizaÃ§Ã£o
cache_aside_set("user:1", {"id": 1, "name": "JoÃ£o Silva"})
print(f"  Cache invalidado")

# Leitura apÃ³s update (cache miss novamente)
start = time.time()
user = cache_aside_get("user:1")
print(f"  Tempo: {(time.time() - start) * 1000:.0f}ms (cache miss apÃ³s update)")


# ============================================================================
# ESTRATÃ‰GIA 2: READ-THROUGH
# ============================================================================

print("\n" + "=" * 70)
print("ESTRATÃ‰GIA 2: READ-THROUGH")
print("=" * 70)

"""
Fluxo:
1. App pede dados do cache
2. Cache verifica se tem
3. Se nÃ£o tem, cache busca do DB
4. Cache armazena e retorna

DiferenÃ§a do Cache-Aside:
  â€¢ Cache-Aside: App Ã© responsÃ¡vel por popular cache
  â€¢ Read-Through: Cache Ã© responsÃ¡vel (transparente para app)

â”Œâ”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App â”‚         â”‚ Cache â”‚         â”‚ Database â”‚
â””â”€â”€â”¬â”€â”€â”˜         â””â”€â”€â”€â”¬â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
   â”‚                â”‚                  â”‚
   â”‚ 1. GET key     â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                  â”‚
   â”‚                â”‚                  â”‚
   â”‚         Cache miss               â”‚
   â”‚                â”‚ 2. SELECT        â”‚
   â”‚                â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                â”‚                  â”‚
   â”‚                â”‚ Data             â”‚
   â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚                â”‚                  â”‚
   â”‚         (Cache stores)            â”‚
   â”‚                â”‚                  â”‚
   â”‚ 3. Data        â”‚                  â”‚
   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚

âœ… PrÃ³s:
  â€¢ Transparente para aplicaÃ§Ã£o
  â€¢ Cache Ã© sempre fonte de verdade
  â€¢ Simplifica cÃ³digo da aplicaÃ§Ã£o

âŒ Contras:
  â€¢ Requer biblioteca/proxy de cache
  â€¢ Mesmo cache miss penalty
  â€¢ Menos flexibilidade

ğŸ¯ Quando usar:
  â€¢ Quer abstrair caching da aplicaÃ§Ã£o
  â€¢ Usando proxy de cache (Varnish, CDN)
  â€¢ PadrÃ£o de acesso consistente
"""


class ReadThroughCache:
    """
    Read-Through Cache implementation.

    Cache busca do DB automaticamente.
    """

    def __init__(self):
        self.cache = {}

    def get(self, key: str) -> Optional[Any]:
        """Get com read-through."""
        # Verificar cache
        cached = self.cache.get(key)

        if cached and cached["expires_at"] > datetime.now():
            print(f"  âœ… Cache HIT (read-through): {key}")
            return cached["value"]

        print(f"  âŒ Cache MISS (read-through): {key}")

        # Cache busca do DB (transparente para app!)
        value = simulate_db_read(key)

        if value is not None:
            # Cache armazena
            self.cache[key] = {
                "value": value,
                "expires_at": datetime.now() + timedelta(seconds=300)
            }

        return value

    def invalidate(self, key: str):
        """Invalidar cache."""
        self.cache.pop(key, None)


# DemonstraÃ§Ã£o
print("\nğŸ“Š DemonstraÃ§Ã£o Read-Through:\n")

rt_cache = ReadThroughCache()

# Primeira leitura (cache miss, cache busca DB)
start = time.time()
user = rt_cache.get("user:1")
print(f"  Tempo: {(time.time() - start) * 1000:.0f}ms")

# Segunda leitura (cache hit)
start = time.time()
user = rt_cache.get("user:1")
print(f"  Tempo: {(time.time() - start) * 1000:.0f}ms")


# ============================================================================
# ESTRATÃ‰GIA 3: WRITE-THROUGH
# ============================================================================

print("\n" + "=" * 70)
print("ESTRATÃ‰GIA 3: WRITE-THROUGH")
print("=" * 70)

"""
Fluxo de escrita:
1. App escreve no cache
2. Cache escreve no DB (sÃ­ncrono)
3. Cache retorna sucesso

â”Œâ”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App â”‚         â”‚ Cache â”‚         â”‚ Database â”‚
â””â”€â”€â”¬â”€â”€â”˜         â””â”€â”€â”€â”¬â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
   â”‚                â”‚                  â”‚
   â”‚ 1. SET key     â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                  â”‚
   â”‚                â”‚                  â”‚
   â”‚                â”‚ 2. INSERT/UPDATE â”‚
   â”‚                â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                â”‚                  â”‚
   â”‚                â”‚ OK               â”‚
   â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚                â”‚                  â”‚
   â”‚         (Cache stores)            â”‚
   â”‚                â”‚                  â”‚
   â”‚ 3. OK          â”‚                  â”‚
   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚

âœ… PrÃ³s:
  â€¢ Cache e DB sempre consistentes
  â€¢ Sem perda de dados se cache falhar
  â€¢ Leituras rÃ¡pidas (sempre no cache)

âŒ Contras:
  â€¢ Escritas lentas (espera DB)
  â€¢ Overhead em toda escrita
  â€¢ Cache pode ter dados nunca lidos

ğŸ¯ Quando usar:
  â€¢ ConsistÃªncia Ã© crÃ­tica
  â€¢ Muitas leituras, poucas escritas
  â€¢ NÃ£o pode perder dados
"""


class WriteThroughCache:
    """Write-Through Cache implementation."""

    def __init__(self):
        self.cache = {}

    def set(self, key: str, value: Any):
        """Set com write-through."""
        # 1. Escrever no DB (sÃ­ncrono!)
        simulate_db_write(key, value)
        print(f"  DB atualizado: {key}")

        # 2. Atualizar cache
        self.cache[key] = {
            "value": value,
            "expires_at": datetime.now() + timedelta(seconds=300)
        }
        print(f"  Cache atualizado: {key}")

    def get(self, key: str) -> Optional[Any]:
        """Get (sempre no cache)."""
        cached = self.cache.get(key)

        if cached and cached["expires_at"] > datetime.now():
            print(f"  âœ… Cache HIT (write-through): {key}")
            return cached["value"]

        # Se nÃ£o estiver no cache, buscar do DB
        value = simulate_db_read(key)
        if value:
            self.cache[key] = {
                "value": value,
                "expires_at": datetime.now() + timedelta(seconds=300)
            }

        return value


# DemonstraÃ§Ã£o
print("\nğŸ“Š DemonstraÃ§Ã£o Write-Through:\n")

wt_cache = WriteThroughCache()

# Escrita (atualiza DB e cache)
start = time.time()
wt_cache.set("user:2", {"id": 2, "name": "Maria"})
print(f"  Tempo de escrita: {(time.time() - start) * 1000:.0f}ms (lento!)")

# Leitura (cache hit, rÃ¡pido)
start = time.time()
user = wt_cache.get("user:2")
print(f"  Tempo de leitura: {(time.time() - start) * 1000:.0f}ms (rÃ¡pido!)")


# ============================================================================
# ESTRATÃ‰GIA 4: WRITE-BEHIND (WRITE-BACK)
# ============================================================================

print("\n" + "=" * 70)
print("ESTRATÃ‰GIA 4: WRITE-BEHIND (WRITE-BACK)")
print("=" * 70)

"""
Fluxo de escrita:
1. App escreve no cache
2. Cache retorna sucesso (imediato!)
3. Cache agenda escrita no DB (assÃ­ncrono)
4. DB Ã© atualizado em background

â”Œâ”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App â”‚         â”‚ Cache â”‚         â”‚ Database â”‚
â””â”€â”€â”¬â”€â”€â”˜         â””â”€â”€â”€â”¬â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
   â”‚                â”‚                  â”‚
   â”‚ 1. SET key     â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                  â”‚
   â”‚                â”‚                  â”‚
   â”‚         (Cache stores)            â”‚
   â”‚                â”‚                  â”‚
   â”‚ 2. OK âœ…       â”‚                  â”‚
   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
   â”‚                â”‚                  â”‚
   â”‚         (Later, async)            â”‚
   â”‚                â”‚ 3. INSERT/UPDATE â”‚
   â”‚                â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚

âœ… PrÃ³s:
  â€¢ Escritas MUITO rÃ¡pidas (nÃ£o espera DB)
  â€¢ Reduz load no DB (batch writes)
  â€¢ Melhor throughput

âŒ Contras:
  â€¢ Risco de perda de dados (se cache falhar)
  â€¢ Complexidade (workers assÃ­ncronos)
  â€¢ Eventual consistency

ğŸ¯ Quando usar:
  â€¢ Escritas muito frequentes
  â€¢ LatÃªncia Ã© crÃ­tica
  â€¢ OK perder alguns dados
  â€¢ Exemplo: contador de views, likes
"""


import threading
import queue


class WriteBehindCache:
    """
    Write-Behind Cache implementation.

    Escreve no cache imediatamente, DB em background.
    """

    def __init__(self):
        self.cache = {}
        self.write_queue = queue.Queue()
        self.running = True

        # Worker thread para escrever no DB
        self.worker = threading.Thread(target=self._background_writer, daemon=True)
        self.worker.start()

    def _background_writer(self):
        """Worker que escreve no DB em background."""
        while self.running:
            try:
                # Pegar item da fila (timeout 1s)
                key, value = self.write_queue.get(timeout=1)

                # Escrever no DB
                simulate_db_write(key, value)
                print(f"  ğŸ“ [Background] DB atualizado: {key}")

                self.write_queue.task_done()
            except queue.Empty:
                continue

    def set(self, key: str, value: Any):
        """Set com write-behind (assÃ­ncrono)."""
        # 1. Atualizar cache (imediato!)
        self.cache[key] = {
            "value": value,
            "expires_at": datetime.now() + timedelta(seconds=300)
        }
        print(f"  âš¡ Cache atualizado (imediato): {key}")

        # 2. Agendar escrita no DB (assÃ­ncrono)
        self.write_queue.put((key, value))

    def get(self, key: str) -> Optional[Any]:
        """Get do cache."""
        cached = self.cache.get(key)

        if cached and cached["expires_at"] > datetime.now():
            return cached["value"]

        return None

    def flush(self):
        """Esperar todas as escritas completarem."""
        self.write_queue.join()

    def stop(self):
        """Parar worker."""
        self.running = False


# DemonstraÃ§Ã£o
print("\nğŸ“Š DemonstraÃ§Ã£o Write-Behind:\n")

wb_cache = WriteBehindCache()

# Escritas (muito rÃ¡pidas!)
start = time.time()
wb_cache.set("user:3", {"id": 3, "name": "Pedro"})
wb_cache.set("user:4", {"id": 4, "name": "Ana"})
print(f"  Tempo de 2 escritas: {(time.time() - start) * 1000:.0f}ms (muito rÃ¡pido!)")

# Leitura (cache hit)
user = wb_cache.get("user:3")
print(f"  Lido do cache: {user}")

# Esperar background writes completarem
print(f"  Esperando writes em background...")
wb_cache.flush()
print(f"  âœ… Todas as escritas completadas")

wb_cache.stop()


# ============================================================================
# ESTRATÃ‰GIA 5: REFRESH-AHEAD
# ============================================================================

print("\n" + "=" * 70)
print("ESTRATÃ‰GIA 5: REFRESH-AHEAD")
print("=" * 70)

"""
Fluxo:
1. Cache detecta que TTL estÃ¡ perto de expirar
2. Cache atualiza dados proativamente (antes de expirar)
3. UsuÃ¡rio sempre tem cache hit

â”Œâ”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App â”‚         â”‚ Cache â”‚         â”‚ Database â”‚
â””â”€â”€â”¬â”€â”€â”˜         â””â”€â”€â”€â”¬â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
   â”‚                â”‚                  â”‚
   â”‚ 1. GET key     â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                  â”‚
   â”‚                â”‚                  â”‚
   â”‚         (TTL < threshold)         â”‚
   â”‚                â”‚ 2. Refresh       â”‚
   â”‚                â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                â”‚                  â”‚
   â”‚ 3. Data (old)  â”‚                  â”‚
   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
   â”‚                â”‚                  â”‚
   â”‚         (Background update)       â”‚

âœ… PrÃ³s:
  â€¢ Sempre cache hit (nunca espera)
  â€¢ Ã“timo para dados frequentemente acessados
  â€¢ UsuÃ¡rio nunca sente cache miss

âŒ Contras:
  â€¢ Atualiza dados nÃ£o usados (desperdÃ­cio)
  â€¢ Complexidade (background refresh)
  â€¢ Mais load no DB

ğŸ¯ Quando usar:
  â€¢ Dados crÃ­ticos de performance
  â€¢ PadrÃ£o de acesso previsÃ­vel
  â€¢ Exemplo: pÃ¡gina inicial, dashboard
"""


class RefreshAheadCache:
    """
    Refresh-Ahead Cache implementation.

    Atualiza cache proativamente antes de expirar.
    """

    def __init__(self, refresh_threshold: float = 0.8):
        self.cache = {}
        self.refresh_threshold = refresh_threshold  # 80% do TTL
        self.ttl = 10  # 10 segundos para demonstraÃ§Ã£o

    def get(self, key: str) -> Optional[Any]:
        """Get com refresh-ahead."""
        cached = self.cache.get(key)

        if cached:
            # Verificar se ainda Ã© vÃ¡lido
            if cached["expires_at"] > datetime.now():
                # Verificar se precisa refresh
                ttl_remaining = (cached["expires_at"] - datetime.now()).total_seconds()
                ttl_percentage = ttl_remaining / self.ttl

                if ttl_percentage < self.refresh_threshold:
                    print(f"  ğŸ”„ Refresh ahead: {key} (TTL em {ttl_remaining:.1f}s)")
                    # Refresh em background (simplificado aqui)
                    self._refresh_async(key)

                print(f"  âœ… Cache HIT (refresh-ahead): {key}")
                return cached["value"]

        # Cache miss: buscar do DB
        print(f"  âŒ Cache MISS (refresh-ahead): {key}")
        value = simulate_db_read(key)

        if value is not None:
            self.cache[key] = {
                "value": value,
                "expires_at": datetime.now() + timedelta(seconds=self.ttl)
            }

        return value

    def _refresh_async(self, key: str):
        """Refresh cache em background."""
        # Em produÃ§Ã£o, usar thread/celery
        # Aqui simplificado
        value = database.get(key)  # Busca sem latÃªncia simulada
        if value:
            self.cache[key] = {
                "value": value,
                "expires_at": datetime.now() + timedelta(seconds=self.ttl)
            }
            print(f"  âœ… Cache refreshed: {key}")


# DemonstraÃ§Ã£o
print("\nğŸ“Š DemonstraÃ§Ã£o Refresh-Ahead:\n")

ra_cache = RefreshAheadCache()

# Adicionar dado no DB
database["user:5"] = {"id": 5, "name": "Carlos"}

# Primeira leitura (cache miss)
user = ra_cache.get("user:5")

# Simular passagem de tempo (80% do TTL)
time.sleep(0.1)  # Simulando

# Segunda leitura (vai refresh em background)
user = ra_cache.get("user:5")


# ============================================================================
# COMPARAÃ‡ÃƒO E BENCHMARKS
# ============================================================================

print("\n" + "=" * 70)
print("COMPARAÃ‡ÃƒO DE PERFORMANCE")
print("=" * 70)

print("""
LatÃªncias tÃ­picas (assumindo DB = 100ms, Cache = 1ms):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OperaÃ§Ã£o         â”‚ Cache-Aside  â”‚ Write-Throughâ”‚ Write-Behind â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Read (hit)       â”‚ 1ms          â”‚ 1ms          â”‚ 1ms          â”‚
â”‚ Read (miss)      â”‚ 101ms        â”‚ 101ms        â”‚ 101ms        â”‚
â”‚ Write            â”‚ 150ms        â”‚ 152ms        â”‚ 2ms âš¡       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† VENCEDORES:

LatÃªncia de leitura:  Todos iguais (1ms com cache hit)
LatÃªncia de escrita:  Write-Behind (2ms) >> Write-Through (152ms)
ConsistÃªncia:         Write-Through >> Write-Behind
Simplicidade:         Cache-Aside >> Write-Behind
""")


# ============================================================================
# DECISÃƒO: QUAL USAR?
# ============================================================================

print("\n" + "=" * 70)
print("ÃRVORE DE DECISÃƒO")
print("=" * 70)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUAL ESTRATÃ‰GIA USAR?                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Seu caso de uso:

ğŸ“– LEITURAS >> ESCRITAS (95% reads)
   â””â”€> Cache-Aside âœ…
       â€¢ PadrÃ£o mais simples
       â€¢ Suporta falhas do cache
       â€¢ Usado por: Facebook, Twitter

ğŸ“ ESCRITAS FREQUENTES + ConsistÃªncia OK
   â””â”€> Write-Behind âœ…
       â€¢ Escritas rÃ¡pidas
       â€¢ Reduz load no DB
       â€¢ Usado por: Contadores, analytics

ğŸ’¾ CONSISTÃŠNCIA CRÃTICA (dados financeiros)
   â””â”€> Write-Through âœ…
       â€¢ Cache e DB sempre sincronizados
       â€¢ Sem perda de dados
       â€¢ Usado por: Banking, e-commerce

ğŸš€ PERFORMANCE CRÃTICA + Dados quentes
   â””â”€> Refresh-Ahead âœ…
       â€¢ Sempre cache hit
       â€¢ Ã“timo para homepage
       â€¢ Usado por: News sites, dashboards

ğŸ“Š ESTATÃSTICAS DA INDÃšSTRIA:

  Cache-Aside:    70% dos casos (padrÃ£o)
  Write-Through:  15% dos casos (consistÃªncia)
  Write-Behind:   10% dos casos (high-throughput)
  Read-Through:   3% dos casos (proxy)
  Refresh-Ahead:  2% dos casos (crÃ­tico)

ğŸ’¡ COMBINAÃ‡Ã•ES COMUNS:

  â€¢ Cache-Aside (leitura) + Write-Through (escrita)
  â€¢ Cache-Aside (leitura) + Write-Behind (escrita)
  â€¢ Read-Through + Write-Behind
""")


# ============================================================================
# PATTERNS AVANÃ‡ADOS
# ============================================================================

print("\n" + "=" * 70)
print("PATTERNS AVANÃ‡ADOS")
print("=" * 70)

print("""
ğŸ”¹ Cache Warming (Pre-populating)
   â€¢ Popular cache antes de lanÃ§ar feature
   â€¢ Evita thundering herd
   â€¢ Script: for key in hot_keys: cache.set(key, db.get(key))

ğŸ”¹ Cache Stampede Prevention
   â€¢ Problema: 1000 requests simultÃ¢neos apÃ³s cache miss
   â€¢ SoluÃ§Ã£o: Lock (apenas 1 request busca DB)

   def get_with_lock(key):
       cached = cache.get(key)
       if cached:
           return cached

       # Tentar obter lock
       if cache.set_nx(f"lock:{key}", "1", ttl=10):
           # Buscar do DB
           value = db.get(key)
           cache.set(key, value)
           cache.delete(f"lock:{key}")
           return value
       else:
           # Outro thread estÃ¡ buscando, aguardar
           time.sleep(0.1)
           return get_with_lock(key)  # Retry

ğŸ”¹ Two-Level Caching (L1 + L2)
   â€¢ L1: In-process (Python dict) - muito rÃ¡pido
   â€¢ L2: Redis - compartilhado entre servidores

   def get_two_level(key):
       # L1 (local)
       if key in local_cache:
           return local_cache[key]

       # L2 (Redis)
       value = redis.get(key)
       if value:
           local_cache[key] = value  # Popular L1
           return value

       # Miss: buscar DB
       value = db.get(key)
       redis.set(key, value)
       local_cache[key] = value
       return value

ğŸ”¹ Cache Tags (InvalidaÃ§Ã£o em grupo)
   â€¢ Tag: "user:1" â†’ posts:1, posts:2, comments:5
   â€¢ Invalidar tudo: cache.invalidate_tag("user:1")

ğŸ”¹ Probabilistic Early Expiration
   â€¢ Evita thundering herd
   â€¢ Expira cache cedo probabilisticamente

   def get_probabilistic(key):
       cached = cache.get_with_ttl(key)
       if not cached:
           return fetch_and_cache(key)

       value, ttl = cached
       # Expirar probabilisticamente
       beta = 1.0
       delta = time.time() - cached.created_at
       expiry = -beta * ttl * log(random.random())

       if delta > expiry:
           # Refresh proativamente
           return fetch_and_cache(key)

       return value
""")


# ============================================================================
# CONCLUSÃƒO
# ============================================================================

print("\n" + "=" * 70)
print("CONCLUSÃƒO")
print("=" * 70)

print("""
ğŸ¯ RECOMENDAÃ‡ÃƒO GERAL:

Para 90% dos casos:
  â†’ Cache-Aside (Lazy Loading)

Por quÃª?
  âœ… Simples de implementar
  âœ… Tolerante a falhas
  âœ… Armazena apenas dados usados
  âœ… PadrÃ£o da indÃºstria

Evolua quando necessÃ¡rio:
  â€¢ High-write load â†’ Write-Behind
  â€¢ CrÃ­tico consistÃªncia â†’ Write-Through
  â€¢ Performance mÃ¡xima â†’ Refresh-Ahead

ğŸ“Š MÃ‰TRICAS PARA MONITORAR:

  â€¢ Hit Rate: % de cache hits (alvo: >90%)
  â€¢ Miss Penalty: Tempo de cache miss (alvo: <200ms)
  â€¢ Eviction Rate: % de itens evictados (alvo: <10%)
  â€¢ Memory Usage: % de memÃ³ria cache (alvo: <80%)

ğŸš€ PRÃ“XIMOS PASSOS:

  1. Implementar Cache-Aside em seu projeto
  2. Monitorar hit rate
  3. Adicionar cache warming para dados quentes
  4. Considerar Write-Behind se hit rate < 80%

ğŸ’¡ LEMBRE-SE:

"There are only two hard things in Computer Science:
 cache invalidation and naming things."
 - Phil Karlton

Mantenha simples! ğŸ¯
""")

if __name__ == "__main__":
    print("\n\nğŸ“ Execute este script para ver todas as demonstraÃ§Ãµes!")

"""
Exemplo 02: Threads vs Processes vs Async

Demonstra as diferenÃ§as entre threading, multiprocessing e async/await,
mostrando quando usar cada abordagem.
"""

import time
import threading
import multiprocessing
import asyncio
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor


# ============================================================================
# TAREFAS DE TESTE
# ============================================================================

def tarefa_cpu_bound(n):
    """
    Tarefa que usa CPU intensivamente (cÃ¡lculos).
    Exemplo: processamento de imagens, machine learning, criptografia.
    """
    total = 0
    for i in range(n):
        total += i ** 2
    return total


def tarefa_io_bound():
    """
    Tarefa que espera por I/O (rede, disco, banco de dados).
    Exemplo: requisiÃ§Ãµes HTTP, consultas SQL, leitura de arquivos.
    """
    time.sleep(1)  # Simula chamada de API ou query de banco
    return "Dados recebidos"


async def tarefa_async_io():
    """
    Tarefa assÃ­ncrona que espera por I/O.
    """
    await asyncio.sleep(1)  # Simula I/O assÃ­ncrono
    return "Dados recebidos (async)"


# ============================================================================
# EXEMPLO 1: CPU-BOUND - THREADS vs PROCESSES
# ============================================================================

def exemplo_cpu_bound():
    """
    Threads NÃƒO ajudam com CPU-bound devido ao GIL.
    Processes SIM ajudam pois cada processo tem seu prÃ³prio GIL.
    """
    print("\n" + "=" * 60)
    print("EXEMPLO 1: CPU-BOUND (cÃ¡lculos pesados)")
    print("=" * 60)

    n_tarefas = 4
    tamanho = 5_000_000

    # 1. SÃNCRONO (baseline)
    print("\n1. ExecuÃ§Ã£o SÃNCRONA:")
    start = time.time()
    for _ in range(n_tarefas):
        tarefa_cpu_bound(tamanho)
    tempo_sync = time.time() - start
    print(f"   Tempo: {tempo_sync:.2f}s")

    # 2. THREADS (nÃ£o ajuda devido ao GIL!)
    print("\n2. ExecuÃ§Ã£o com THREADS:")
    start = time.time()
    threads = []
    for _ in range(n_tarefas):
        t = threading.Thread(target=tarefa_cpu_bound, args=(tamanho,))
        threads.append(t)
        t.start()

    for t in threads:
        t.join()

    tempo_threads = time.time() - start
    print(f"   Tempo: {tempo_threads:.2f}s")
    print(f"   Speedup: {tempo_sync / tempo_threads:.2f}x")
    print(f"   âŒ Threads nÃ£o ajudaram! (GIL impede paralelismo real)")

    # 3. PROCESSES (funciona!)
    print("\n3. ExecuÃ§Ã£o com PROCESSES:")
    start = time.time()

    with ProcessPoolExecutor(max_workers=n_tarefas) as executor:
        futures = [executor.submit(tarefa_cpu_bound, tamanho) for _ in range(n_tarefas)]
        resultados = [f.result() for f in futures]

    tempo_processes = time.time() - start
    print(f"   Tempo: {tempo_processes:.2f}s")
    print(f"   Speedup: {tempo_sync / tempo_processes:.2f}x")
    print(f"   âœ… Processes funcionaram! (cada processo tem seu GIL)")

    print("\nğŸ“Š RESUMO:")
    print(f"   SÃ­ncrono:   {tempo_sync:.2f}s (baseline)")
    print(f"   Threads:    {tempo_threads:.2f}s ({tempo_sync/tempo_threads:.2f}x)")
    print(f"   Processes:  {tempo_processes:.2f}s ({tempo_sync/tempo_processes:.2f}x)")


# ============================================================================
# EXEMPLO 2: I/O-BOUND - THREADS vs ASYNC
# ============================================================================

def exemplo_io_bound():
    """
    Para I/O-bound, tanto threads quanto async funcionam bem.
    Async geralmente Ã© mais eficiente (menos overhead).
    """
    print("\n" + "=" * 60)
    print("EXEMPLO 2: I/O-BOUND (espera por rede/disco)")
    print("=" * 60)

    n_tarefas = 10

    # 1. SÃNCRONO (baseline)
    print("\n1. ExecuÃ§Ã£o SÃNCRONA:")
    start = time.time()
    for _ in range(n_tarefas):
        tarefa_io_bound()
    tempo_sync = time.time() - start
    print(f"   Tempo: {tempo_sync:.2f}s")
    print(f"   (Cada tarefa demora 1s, total = {n_tarefas}s)")

    # 2. THREADS (funciona bem!)
    print("\n2. ExecuÃ§Ã£o com THREADS:")
    start = time.time()

    with ThreadPoolExecutor(max_workers=n_tarefas) as executor:
        futures = [executor.submit(tarefa_io_bound) for _ in range(n_tarefas)]
        resultados = [f.result() for f in futures]

    tempo_threads = time.time() - start
    print(f"   Tempo: {tempo_threads:.2f}s")
    print(f"   Speedup: {tempo_sync / tempo_threads:.2f}x")
    print(f"   âœ… Threads funcionaram! (I/O libera o GIL)")

    # 3. ASYNC (mais eficiente!)
    print("\n3. ExecuÃ§Ã£o com ASYNC:")
    start = time.time()

    async def executar_async():
        tasks = [tarefa_async_io() for _ in range(n_tarefas)]
        return await asyncio.gather(*tasks)

    asyncio.run(executar_async())

    tempo_async = time.time() - start
    print(f"   Tempo: {tempo_async:.2f}s")
    print(f"   Speedup: {tempo_sync / tempo_async:.2f}x")
    print(f"   âœ… Async funcionou! (menos overhead que threads)")

    print("\nğŸ“Š RESUMO:")
    print(f"   SÃ­ncrono:  {tempo_sync:.2f}s (baseline)")
    print(f"   Threads:   {tempo_threads:.2f}s ({tempo_sync/tempo_threads:.2f}x)")
    print(f"   Async:     {tempo_async:.2f}s ({tempo_sync/tempo_async:.2f}x)")


# ============================================================================
# EXEMPLO 3: OVERHEAD DE CRIAÃ‡ÃƒO
# ============================================================================

def tarefa_rapida():
    """Tarefa muito rÃ¡pida para medir overhead."""
    return sum(range(1000))


def exemplo_overhead():
    """
    Comparar overhead de criaÃ§Ã£o de threads vs processes.
    """
    print("\n" + "=" * 60)
    print("EXEMPLO 3: OVERHEAD DE CRIAÃ‡ÃƒO")
    print("=" * 60)

    n_tarefas = 100

    # Threads (overhead baixo)
    print("\n1. Criando 100 THREADS:")
    start = time.time()
    threads = [threading.Thread(target=tarefa_rapida) for _ in range(n_tarefas)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    tempo_threads = time.time() - start
    print(f"   Tempo: {tempo_threads:.3f}s")

    # Processes (overhead alto)
    print("\n2. Criando 100 PROCESSES:")
    start = time.time()
    with ProcessPoolExecutor(max_workers=4) as executor:  # Pool reutiliza workers
        futures = [executor.submit(tarefa_rapida) for _ in range(n_tarefas)]
        [f.result() for f in futures]
    tempo_processes = time.time() - start
    print(f"   Tempo: {tempo_processes:.3f}s")

    print("\nğŸ“Š CONCLUSÃƒO:")
    print(f"   Threads sÃ£o {tempo_processes/tempo_threads:.1f}x mais rÃ¡pidas para criar")
    print(f"   Use processes apenas quando o trabalho compensar o overhead!")


# ============================================================================
# EXEMPLO 4: COMPARTILHAMENTO DE MEMÃ“RIA
# ============================================================================

# VariÃ¡vel global
contador_global = 0
lock = threading.Lock()


def incrementar_sem_lock():
    """PROBLEMA: Race condition!"""
    global contador_global
    for _ in range(100_000):
        contador_global += 1  # OperaÃ§Ã£o NÃƒO atÃ´mica!


def incrementar_com_lock():
    """SOLUÃ‡ÃƒO: Usar lock."""
    global contador_global
    for _ in range(100_000):
        with lock:
            contador_global += 1


def exemplo_compartilhamento():
    """
    Threads compartilham memÃ³ria â†’ Race conditions!
    Processes tÃªm memÃ³ria isolada â†’ Sem race conditions, mas precisa IPC.
    """
    print("\n" + "=" * 60)
    print("EXEMPLO 4: COMPARTILHAMENTO DE MEMÃ“RIA")
    print("=" * 60)

    global contador_global

    # Problema: Race condition com threads
    print("\n1. THREADS SEM LOCK (race condition):")
    contador_global = 0
    threads = [threading.Thread(target=incrementar_sem_lock) for _ in range(4)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    print(f"   Esperado: 400.000")
    print(f"   Obtido:   {contador_global:,}")
    print(f"   âŒ Resultado incorreto! (race condition)")

    # SoluÃ§Ã£o: Lock
    print("\n2. THREADS COM LOCK (correto mas lento):")
    contador_global = 0
    start = time.time()
    threads = [threading.Thread(target=incrementar_com_lock) for _ in range(4)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    print(f"   Esperado: 400.000")
    print(f"   Obtido:   {contador_global:,}")
    print(f"   Tempo:    {time.time() - start:.3f}s")
    print(f"   âœ… Resultado correto, mas locks tÃªm overhead!")

    # Processes: memÃ³ria isolada
    print("\n3. PROCESSES (memÃ³ria isolada):")
    print("   Cada processo tem sua prÃ³pria cÃ³pia das variÃ¡veis")
    print("   NÃ£o hÃ¡ race conditions, mas precisa usar multiprocessing.Value")
    print("   ou Queue para comunicaÃ§Ã£o entre processos.")


# ============================================================================
# EXEMPLO 5: CASOS DE USO REAIS
# ============================================================================

def exemplo_casos_de_uso():
    """
    Guia de quando usar cada abordagem.
    """
    print("\n" + "=" * 60)
    print("EXEMPLO 5: QUANDO USAR CADA ABORDAGEM?")
    print("=" * 60)

    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CenÃ¡rio         â”‚ SÃ­ncrono     â”‚ Threads     â”‚ Processes    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Web Scraping    â”‚ âŒ Muito     â”‚ âœ… Bom      â”‚ âš ï¸ Overkill  â”‚
â”‚ (muitas URLs)   â”‚    lento     â”‚             â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ API Requests    â”‚ âŒ Muito     â”‚ âœ… Bom      â”‚ âš ï¸ Overkill  â”‚
â”‚ (I/O-bound)     â”‚    lento     â”‚             â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Async/Await     â”‚ âŒ Lento     â”‚ âš ï¸ Misto    â”‚ âŒ NÃ£o usa   â”‚
â”‚ (I/O-bound)     â”‚              â”‚             â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Image           â”‚ âŒ Muito     â”‚ âŒ GIL      â”‚ âœ… Perfeito  â”‚
â”‚ Processing      â”‚    lento     â”‚  bloqueia   â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Machine         â”‚ âŒ Muito     â”‚ âŒ GIL      â”‚ âœ… Perfeito  â”‚
â”‚ Learning        â”‚    lento     â”‚  bloqueia   â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Video Encoding  â”‚ âŒ Muito     â”‚ âŒ GIL      â”‚ âœ… Perfeito  â”‚
â”‚ (FFmpeg)        â”‚    lento     â”‚  bloqueia   â”‚              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Database        â”‚ âš ï¸ OK para  â”‚ âœ… Melhor   â”‚ âš ï¸ Overkill  â”‚
â”‚ Queries         â”‚  poucos      â”‚             â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ REGRAS DE OURO:

1. CPU-bound (cÃ¡lculos pesados)
   â†’ Use MULTIPROCESSING ou bibliotecas em C (NumPy, Pandas)

2. I/O-bound (rede, disco, DB)
   â†’ Use ASYNC/AWAIT (melhor) ou THREADS (mais simples)

3. I/O-bound com biblioteca sÃ­ncrona (requests, nÃ£o aiohttp)
   â†’ Use THREADS (nÃ£o pode usar async)

4. Mix de CPU e I/O
   â†’ Use ASYNC + ProcessPoolExecutor para CPU parts

5. Muitas tarefas pequenas
   â†’ Use ThreadPoolExecutor ou ProcessPoolExecutor (pools reutilizam workers)

6. Real-time / Low latency
   â†’ Use ASYNC (menos overhead de context switching)
    """)


# ============================================================================
# EXEMPLO 6: PADRÃƒO HÃBRIDO (ASYNC + PROCESSES)
# ============================================================================

async def exemplo_hibrido():
    """
    Combinar async para I/O com processes para CPU.
    PadrÃ£o usado em aplicaÃ§Ãµes reais!
    """
    print("\n" + "=" * 60)
    print("EXEMPLO 6: PADRÃƒO HÃBRIDO (ASYNC + PROCESSES)")
    print("=" * 60)

    print("\nCenÃ¡rio: Baixar imagens (I/O) e processar (CPU)")

    async def baixar_imagem(url_id):
        """Simula download de imagem (I/O-bound)"""
        await asyncio.sleep(0.1)  # Simula latÃªncia de rede
        return f"imagem_{url_id}.jpg", [url_id] * 1000  # Dados da imagem

    def processar_imagem(dados):
        """Simula processamento de imagem (CPU-bound)"""
        nome, pixels = dados
        # Processamento pesado
        resultado = sum([p ** 2 for p in pixels])
        return f"{nome}_processada", resultado

    # Executar hÃ­brido
    start = time.time()

    # Passo 1: Download assÃ­ncrono (I/O-bound)
    print("\n1. Baixando 10 imagens (async)...")
    imagens = await asyncio.gather(*[baixar_imagem(i) for i in range(10)])
    print(f"   Download completo: {time.time() - start:.2f}s")

    # Passo 2: Processamento paralelo (CPU-bound)
    print("\n2. Processando imagens (multiprocessing)...")
    loop = asyncio.get_event_loop()
    with ProcessPoolExecutor(max_workers=4) as executor:
        # Usar run_in_executor para integrar com async
        futures = [
            loop.run_in_executor(executor, processar_imagem, img)
            for img in imagens
        ]
        resultados = await asyncio.gather(*futures)

    tempo_total = time.time() - start
    print(f"   Processamento completo: {tempo_total:.2f}s")
    print(f"\nâœ… Total: {tempo_total:.2f}s")
    print("   Melhor dos dois mundos: async para I/O + processes para CPU!")


# ============================================================================
# MAIN
# ============================================================================

def main():
    print("=" * 60)
    print("THREADS vs PROCESSES vs ASYNC")
    print("=" * 60)

    exemplo_cpu_bound()
    exemplo_io_bound()
    exemplo_overhead()
    exemplo_compartilhamento()
    exemplo_casos_de_uso()

    # Exemplo hÃ­brido (async)
    print("\n" + "=" * 60)
    asyncio.run(exemplo_hibrido())

    print("\n" + "=" * 60)
    print("RESUMO FINAL")
    print("=" * 60)
    print("""
âœ… CPU-BOUND:     Use MULTIPROCESSING
âœ… I/O-BOUND:     Use ASYNC/AWAIT (ou THREADS se biblioteca Ã© sÃ­ncrona)
âœ… HÃBRIDO:       Combine ASYNC (I/O) + PROCESSES (CPU)
âœ… SIMPLICIDADE:  Use ThreadPoolExecutor/ProcessPoolExecutor

âŒ NUNCA:         Use threads para CPU-bound (GIL vai bloquear)
âŒ CUIDADO:       Threads + memÃ³ria compartilhada = race conditions
    """)


if __name__ == "__main__":
    # Note: Em alguns sistemas, multiprocessing precisa de if __name__ == "__main__"
    main()

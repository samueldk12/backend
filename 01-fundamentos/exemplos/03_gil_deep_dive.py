"""
Exemplo 03: Deep Dive no GIL (Global Interpreter Lock)

Demonstra como o GIL funciona, suas limitaÃ§Ãµes e como contornÃ¡-lo.
"""

import time
import threading
import multiprocessing
import sys
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor


def mostrar_info_gil():
    """InformaÃ§Ãµes sobre o GIL."""
    print("=" * 60)
    print("O QUE Ã‰ O GIL?")
    print("=" * 60)
    print("""
O Global Interpreter Lock (GIL) Ã© um mutex que protege acesso aos
objetos Python, impedindo que mÃºltiplas threads executem cÃ³digo
Python simultaneamente.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Por que o GIL existe?                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Simplificar gerenciamento de memÃ³ria (refcount)     â”‚
â”‚ 2. Facilitar integraÃ§Ã£o com bibliotecas C              â”‚
â”‚ 3. ImplementaÃ§Ã£o mais simples do interpretador         â”‚
â”‚ 4. Melhor performance single-threaded                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Quando o GIL Ã© liberado?                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… Durante operaÃ§Ãµes de I/O (read, write, network)     â”‚
â”‚ âœ… Durante chamadas a bibliotecas C (NumPy, PIL)       â”‚
â”‚ âœ… Durante time.sleep()                                 â”‚
â”‚ âŒ Durante execuÃ§Ã£o de bytecode Python puro            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    print(f"VersÃ£o do Python: {sys.version}")
    print(f"GIL switch interval: {sys.getswitchinterval()}s")
    print("(Python troca de thread a cada 5ms por padrÃ£o)")


# ============================================================================
# DEMONSTRAÃ‡ÃƒO 1: GIL EM AÃ‡ÃƒO
# ============================================================================

def demonstrar_gil_cpu():
    """Mostrar que GIL impede paralelismo em CPU-bound."""
    print("\n" + "=" * 60)
    print("DEMO 1: GIL IMPEDINDO PARALELISMO (CPU-BOUND)")
    print("=" * 60)

    def trabalho_cpu(n, nome):
        """Tarefa CPU-bound."""
        print(f"  [{nome}] Iniciando...")
        resultado = 0
        for i in range(n):
            resultado += i ** 2
        print(f"  [{nome}] ConcluÃ­do!")
        return resultado

    n = 10_000_000

    # 1 Thread (baseline)
    print("\n1. UMA THREAD:")
    start = time.time()
    trabalho_cpu(n, "T1")
    tempo_1_thread = time.time() - start
    print(f"Tempo: {tempo_1_thread:.2f}s")

    # 2 Threads (nÃ£o deve ser 2x mais rÃ¡pido devido ao GIL!)
    print("\n2. DUAS THREADS:")
    start = time.time()
    t1 = threading.Thread(target=trabalho_cpu, args=(n, "T1"))
    t2 = threading.Thread(target=trabalho_cpu, args=(n, "T2"))
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    tempo_2_threads = time.time() - start
    print(f"Tempo: {tempo_2_threads:.2f}s")
    print(f"Speedup: {tempo_1_thread / tempo_2_threads:.2f}x")
    print(f"âŒ NÃ£o Ã© 2x mais rÃ¡pido! GIL forÃ§a serializaÃ§Ã£o.")

    # 2 Processes (deve ser ~2x mais rÃ¡pido!)
    print("\n3. DOIS PROCESSOS:")
    start = time.time()
    p1 = multiprocessing.Process(target=trabalho_cpu, args=(n, "P1"))
    p2 = multiprocessing.Process(target=trabalho_cpu, args=(n, "P2"))
    p1.start()
    p2.start()
    p1.join()
    p2.join()
    tempo_2_processes = time.time() - start
    print(f"Tempo: {tempo_2_processes:.2f}s")
    print(f"Speedup: {tempo_1_thread / tempo_2_processes:.2f}x")
    print(f"âœ… Quase 2x mais rÃ¡pido! Cada processo tem seu GIL.")


# ============================================================================
# DEMONSTRAÃ‡ÃƒO 2: GIL SENDO LIBERADO (I/O)
# ============================================================================

def demonstrar_gil_io():
    """Mostrar que GIL Ã© liberado durante I/O."""
    print("\n" + "=" * 60)
    print("DEMO 2: GIL SENDO LIBERADO (I/O-BOUND)")
    print("=" * 60)

    def trabalho_io(duracao, nome):
        """Tarefa I/O-bound."""
        print(f"  [{nome}] Iniciando sleep({duracao}s)...")
        time.sleep(duracao)  # GIL Ã© liberado aqui!
        print(f"  [{nome}] Acordou!")
        return nome

    # Sequencial
    print("\n1. SEQUENCIAL:")
    start = time.time()
    trabalho_io(1, "T1")
    trabalho_io(1, "T2")
    trabalho_io(1, "T3")
    tempo_seq = time.time() - start
    print(f"Tempo: {tempo_seq:.2f}s")

    # Threads (deve ser ~3x mais rÃ¡pido!)
    print("\n2. TRÃŠS THREADS:")
    start = time.time()
    threads = [
        threading.Thread(target=trabalho_io, args=(1, f"T{i}"))
        for i in range(1, 4)
    ]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    tempo_threads = time.time() - start
    print(f"Tempo: {tempo_threads:.2f}s")
    print(f"Speedup: {tempo_seq / tempo_threads:.2f}x")
    print(f"âœ… Threads funcionaram! GIL foi liberado durante sleep.")


# ============================================================================
# DEMONSTRAÃ‡ÃƒO 3: BIBLIOTECAS C LIBERAM GIL
# ============================================================================

def demonstrar_bibliotecas_c():
    """Mostrar que bibliotecas em C liberam o GIL."""
    print("\n" + "=" * 60)
    print("DEMO 3: BIBLIOTECAS C LIBERAM O GIL")
    print("=" * 60)

    try:
        import numpy as np

        def trabalho_numpy(tamanho):
            """OperaÃ§Ã£o NumPy (C code)."""
            arr = np.arange(tamanho)
            return np.sum(arr ** 2)  # NumPy libera GIL!

        tamanho = 10_000_000

        # 1 Thread
        print("\n1. UMA THREAD (NumPy):")
        start = time.time()
        trabalho_numpy(tamanho)
        tempo_1 = time.time() - start
        print(f"Tempo: {tempo_1:.2f}s")

        # 4 Threads
        print("\n2. QUATRO THREADS (NumPy):")
        start = time.time()
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(trabalho_numpy, tamanho) for _ in range(4)]
            [f.result() for f in futures]
        tempo_4 = time.time() - start
        print(f"Tempo: {tempo_4:.2f}s")
        print(f"Speedup: {tempo_1 * 4 / tempo_4:.2f}x")
        print(f"âœ… NumPy libera GIL, threads funcionam em paralelo!")

    except ImportError:
        print("\nâŒ NumPy nÃ£o instalado. Execute: pip install numpy")
        print("NumPy Ã© escrito em C e libera o GIL durante operaÃ§Ãµes.")


# ============================================================================
# DEMONSTRAÃ‡ÃƒO 4: GIL CONTENTION (COMPETIÃ‡ÃƒO)
# ============================================================================

def demonstrar_gil_contention():
    """
    Mostrar que muitas threads competindo pelo GIL podem ser
    PIORES que cÃ³digo single-threaded devido ao overhead.
    """
    print("\n" + "=" * 60)
    print("DEMO 4: GIL CONTENTION (THRASHING)")
    print("=" * 60)

    def trabalho_leve():
        """Trabalho muito leve (mais tempo trocando GIL que trabalhando)."""
        total = 0
        for i in range(100_000):
            total += i
        return total

    # 1 Thread
    print("\n1. SEQUENCIAL (100 tarefas):")
    start = time.time()
    for _ in range(100):
        trabalho_leve()
    tempo_seq = time.time() - start
    print(f"Tempo: {tempo_seq:.3f}s")

    # Muitas threads (overhead de GIL switching!)
    print("\n2. 100 THREADS (100 tarefas):")
    start = time.time()
    threads = [threading.Thread(target=trabalho_leve) for _ in range(100)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    tempo_threads = time.time() - start
    print(f"Tempo: {tempo_threads:.3f}s")
    print(f"Speedup: {tempo_seq / tempo_threads:.2f}x")
    if tempo_threads > tempo_seq:
        print(f"âŒ Threads foram MAIS LENTAS! (GIL contention)")
    else:
        print(f"âš ï¸ Threads nÃ£o trouxeram benefÃ­cio significativo.")

    # ThreadPool (reutiliza threads, menos overhead)
    print("\n3. THREADPOOL com 4 workers (100 tarefas):")
    start = time.time()
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(trabalho_leve) for _ in range(100)]
        [f.result() for f in futures]
    tempo_pool = time.time() - start
    print(f"Tempo: {tempo_pool:.3f}s")
    print(f"Speedup: {tempo_seq / tempo_pool:.2f}x")
    print(f"âœ… ThreadPool Ã© melhor (menos overhead de criaÃ§Ã£o).")


# ============================================================================
# DEMONSTRAÃ‡ÃƒO 5: COMO CONTORNAR O GIL
# ============================================================================

def demonstrar_solucoes():
    """EstratÃ©gias para lidar com o GIL."""
    print("\n" + "=" * 60)
    print("DEMO 5: ESTRATÃ‰GIAS PARA LIDAR COM O GIL")
    print("=" * 60)

    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SOLUÃ‡Ã•ES PARA O GIL                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚ 1ï¸âƒ£ MULTIPROCESSING                                        â”‚
â”‚    âœ… Contorna GIL (cada processo tem seu prÃ³prio)        â”‚
â”‚    âŒ Overhead de criaÃ§Ã£o e comunicaÃ§Ã£o                   â”‚
â”‚    ğŸ“ Use para: CPU-bound tasks                           â”‚
â”‚                                                            â”‚
â”‚ 2ï¸âƒ£ ASYNC/AWAIT                                            â”‚
â”‚    âœ… Eficiente para I/O-bound                            â”‚
â”‚    âœ… Menos overhead que threads                          â”‚
â”‚    âŒ NÃ£o ajuda com CPU-bound                             â”‚
â”‚    ğŸ“ Use para: APIs, web scraping, database queries      â”‚
â”‚                                                            â”‚
â”‚ 3ï¸âƒ£ BIBLIOTECAS EM C                                       â”‚
â”‚    âœ… NumPy, Pandas, PIL liberam GIL                      â”‚
â”‚    âœ… Performance prÃ³xima de C                            â”‚
â”‚    ğŸ“ Use para: processamento de dados, ML                â”‚
â”‚                                                            â”‚
â”‚ 4ï¸âƒ£ JYTHON / IronPython                                    â”‚
â”‚    âœ… NÃ£o tÃªm GIL                                         â”‚
â”‚    âŒ Menos bibliotecas disponÃ­veis                       â”‚
â”‚    âŒ NÃ£o tÃ£o atualizados                                 â”‚
â”‚                                                            â”‚
â”‚ 5ï¸âƒ£ PYPY (JIT Compiler)                                    â”‚
â”‚    âœ… Mais rÃ¡pido que CPython                             â”‚
â”‚    âš ï¸ Ainda tem GIL                                       â”‚
â”‚    ğŸ“ Use para: CPU-bound pure Python                     â”‚
â”‚                                                            â”‚
â”‚ 6ï¸âƒ£ NOGIL PROJECT (Python 3.13+)                           â”‚
â”‚    ğŸš§ Em desenvolvimento                                  â”‚
â”‚    ğŸ¯ Remover GIL do CPython                              â”‚
â”‚    â³ Futuro do Python                                    â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š ÃRVORE DE DECISÃƒO:

Seu cÃ³digo Ã© CPU-bound ou I/O-bound?
â”‚
â”œâ”€ CPU-BOUND (cÃ¡lculos, processamento)
â”‚  â”‚
â”‚  â”œâ”€ Pode usar NumPy/Pandas?
â”‚  â”‚  â””â”€ SIM â†’ Use NumPy/Pandas (libera GIL) âœ…
â”‚  â”‚
â”‚  â””â”€ Python puro?
â”‚     â””â”€ Use multiprocessing.Pool âœ…
â”‚
â””â”€ I/O-BOUND (network, disk, database)
   â”‚
   â”œâ”€ Bibliotecas suportam async?
   â”‚  â””â”€ SIM â†’ Use async/await âœ… (melhor)
   â”‚
   â””â”€ Bibliotecas sÃ£o sÃ­ncronas?
      â””â”€ Use ThreadPoolExecutor âœ…

    """)


# ============================================================================
# DEMONSTRAÃ‡ÃƒO 6: EXEMPLO PRÃTICO (Web Scraping)
# ============================================================================

def demonstrar_caso_real():
    """Caso real: web scraping."""
    print("\n" + "=" * 60)
    print("DEMO 6: CASO REAL - WEB SCRAPING")
    print("=" * 60)

    def simular_download(url_id):
        """Simula download de uma pÃ¡gina web."""
        time.sleep(0.1)  # Simula latÃªncia de rede
        return f"ConteÃºdo da URL {url_id}"

    n_urls = 20

    # Sequencial
    print(f"\n1. SEQUENCIAL ({n_urls} URLs):")
    start = time.time()
    for i in range(n_urls):
        simular_download(i)
    tempo_seq = time.time() - start
    print(f"Tempo: {tempo_seq:.2f}s")

    # Threads (ideal para I/O!)
    print(f"\n2. THREADS ({n_urls} URLs):")
    start = time.time()
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(simular_download, i) for i in range(n_urls)]
        resultados = [f.result() for f in futures]
    tempo_threads = time.time() - start
    print(f"Tempo: {tempo_threads:.2f}s")
    print(f"Speedup: {tempo_seq / tempo_threads:.2f}x")
    print(f"âœ… {tempo_threads:.2f}s vs {tempo_seq:.2f}s sequencial!")


# ============================================================================
# MAIN
# ============================================================================

def main():
    mostrar_info_gil()
    demonstrar_gil_cpu()
    demonstrar_gil_io()
    demonstrar_bibliotecas_c()
    demonstrar_gil_contention()
    demonstrar_solucoes()
    demonstrar_caso_real()

    print("\n" + "=" * 60)
    print("RESUMO FINAL")
    print("=" * 60)
    print("""
ğŸ”’ GIL: Global Interpreter Lock
   â””â”€ Mutex que impede execuÃ§Ã£o paralela de cÃ³digo Python

âœ… QUANDO GIL NÃƒO Ã‰ PROBLEMA:
   â€¢ I/O-bound tasks (GIL Ã© liberado)
   â€¢ Bibliotecas em C (NumPy, Pandas, PIL)
   â€¢ Single-threaded code

âŒ QUANDO GIL Ã‰ PROBLEMA:
   â€¢ CPU-bound com threads
   â€¢ Processamento paralelo em Python puro

ğŸ¯ SOLUÃ‡Ã•ES:
   â€¢ CPU-bound â†’ multiprocessing
   â€¢ I/O-bound â†’ async/await ou threads
   â€¢ Mix â†’ async + ProcessPoolExecutor

ğŸš€ FUTURO:
   â€¢ Python 3.13+ pode remover GIL (nogil project)
   â€¢ Enquanto isso, use as soluÃ§Ãµes acima!
    """)


if __name__ == "__main__":
    main()
